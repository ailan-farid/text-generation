{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small-text-generation-word.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTbJqGFwbrjR",
        "colab_type": "text"
      },
      "source": [
        "# Mounting google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhHxl4ivpe6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow--gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjwnv_eEbhpz",
        "colab_type": "code",
        "outputId": "dd985369-31e2-43d9-d739-8830ad9be03f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtzEwxVRcxUk",
        "colab_type": "text"
      },
      "source": [
        "# Load modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiUyYUWdcw9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import unicodedata\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTCMZpr7cAga",
        "colab_type": "text"
      },
      "source": [
        "# Load and explore data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9DMvOFRbvhL",
        "colab_type": "code",
        "outputId": "448307b4-4790-4ba6-fd1c-1349a218c89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/text-generation/text-generation-word/nips.csv')\n",
        "df = df[df['Abstract'] != \"Abstract Missing\"]\n",
        "df = df.reset_index(drop=True)\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4933 entries, 0 to 4932\n",
            "Data columns (total 3 columns):\n",
            "Year        4933 non-null int64\n",
            "Title       4933 non-null object\n",
            "Abstract    4933 non-null object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 115.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrmLuvAExrV-",
        "colab_type": "code",
        "outputId": "aafa8381-6784-416a-b893-ab9dc5607193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Select a small dataset\n",
        "df_small = df.iloc[:1500]\n",
        "df_small.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1500 entries, 0 to 1499\n",
            "Data columns (total 3 columns):\n",
            "Year        1500 non-null int64\n",
            "Title       1500 non-null object\n",
            "Abstract    1500 non-null object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 35.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwOrFDY0CpQF",
        "colab_type": "code",
        "outputId": "ec066afa-b1a8-4f39-fd0d-082a45e621ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "text = df_small['Abstract']\n",
        "text.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Up-\u0002propagation is an algorithm for inverting ...\n",
              "1    We have constructed an inexpensive video based...\n",
              "2    Non-negative matrix factorization (NMF) has pr...\n",
              "3    Spike-triggered averaging techniques are effec...\n",
              "4    We consider continuous state, continuous actio...\n",
              "Name: Abstract, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVYcaJm_cvJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_text(index, Series):\n",
        "    example = Series[Series.index == index].values[0]\n",
        "    if len(example) > 0:\n",
        "        print(example)\n",
        "    else:\n",
        "      print('Empty!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT2SHfaBxbOt",
        "colab_type": "code",
        "outputId": "64ff552c-e508-4307-d12e-3e817235c435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "print_text(0,text)\n",
        "print_text(10,text)\n",
        "print_text(20, text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Up-\u0002propagation is an algorithm for inverting and learning neural network\r\n",
            "generative models\u0003 Sensory input is processed by inverting a model that\r\n",
            "generates patterns from hidden variables using top\u0002down connections\u0003\r\n",
            "The inversion process is iterative\u0004 utilizing a negative feedback loop that\r\n",
            "depends on an error signal propagated by bottom\u0002up connections\u0003 The\r\n",
            "error signal is also used to learn the generative model from examples\u0003\r\n",
            "The algorithm is benchmarked against principal component analysis in\r\n",
            "experiments on images of handwritten digits\u0003.\n",
            "Computational models of visual cortex, and in particular those based on sparse coding, have enjoyed much recent attention. Despite this currency, the question of how sparse or how over-complete a sparse representation should be, has gone without principled answer. Here, we use Bayesian model-selection methods to address these questions for a sparse-coding model based on a Student-t prior. Having validated our methods on toy data, we find that natural images are indeed best modelled by extremely sparse distributions; although for the Student-t prior, the associated optimal basis size is only modestly overcomplete.\n",
            "Under natural viewing conditions, human observers shift their gaze to allocate processing resources to subsets of the visual input. Many computational models have aimed at predicting such voluntary attentional shifts. Although the importance of high level stimulus properties (higher order statistics, semantics) stands undisputed, most models are based on low-level features of the input alone. In this study we recorded eye-movements of human observers while they viewed photographs of natural scenes. About two thirds of the stimuli contained at least one person. We demonstrate that a combined model of face detection and low-level saliency clearly outperforms a low-level model in predicting locations humans fixate. This is reflected in our finding fact that observes, even when not instructed to look for anything particular, fixate on a face with a probability of over 80% within their first two fixations (500ms). Remarkably, the model's predictive performance in images that do not contain faces is not impaired by spurious face detector responses, which is suggestive of a bottom-up mechanism for face detection. In summary, we provide a novel computational approach which combines high level object knowledge (in our case: face locations) with low-level features to successfully predict the allocation of attentional resources.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En7K7yeFXnXw",
        "colab_type": "code",
        "outputId": "c553b13c-8c1b-4e1c-8cfe-9c5eca64b1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "corpus_init = ' '.join(list(text))\n",
        "words_init = corpus_init.split()\n",
        "n_words_init = len(words_init)\n",
        "unique_words_init = sorted(list(set(words_init)))\n",
        "n_unique_words_init = len(unique_words_init)\n",
        "print(\"Total number of words before text preprocessing:\", n_words_init)\n",
        "print(\"Total number of unique words before text preprocessing: \", n_unique_words_init)\n",
        "print(unique_words_init[:100])\n",
        "print(unique_words_init[100:200])\n",
        "print(unique_words_init[200:300])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words before text preprocessing: 212975\n",
            "Total number of unique words before text preprocessing:  19055\n",
            "['\"DUOL\"', '\"Expansion-Constrained', '\"Generalized', '\"Hedge\"', '\"autotags\")', '\"averagers,\"', '\"chill\"', '\"disagreement', '\"disappearance\"', '\"expected', '\"external\"', '\"functional', '\"human-like\"', '\"internal\"', '\"isotropic\"', '\"jogging\"', '\"local', '\"missingness\"', '\"naive\"', '\"no\"', '\"nonlinearity\"', '\"shared', '\"simple', '\"skeleton\"', '\"smoothed', '#P', '#P-hard', '$', '$(+\\\\!3,', '$(0,\\\\pi/2]$.', '$(1+(1+\\\\epsilon)\\\\gamma)$-approximate', '$(1+\\\\alpha)\\\\,L^*_\\\\gamma', '$(1+\\\\eps)$', '$(1+\\\\eps)$-approximation', '$(2,', '$(2,1)$-norm', '$(3,', '$(Christopher,', '$(X_1,', '$(\\\\alpha,', '$(\\\\beta,B)$-Bernstein,', '$(has\\\\_husband,', '$(m\\\\gg', '$(x_k)_{k=0}^K$,', '$(x_k)_{k=1}^K$', '$(y_k', '$+$', '$+1$', '$+1/\\\\sqrt{t}$', '$+\\\\!3$', '$-1$', '$-1/\\\\sqrt{t}$', '$0$', '$1', '$1$', '$1$-norm', '$1$.', '$1)$', '$1,', '$1,\\\\infty$', '$1,\\\\infty$-regularized', '$1-\\\\alpha_i$', '$1/\\\\epsilon$', '$1/\\\\epsilon$.', '$10^{64}$', '$10^{70}$', '$11\\\\%$', '$14\\\\%$', '$14\\\\epsilon', '$1\\\\leq', '$2)$', '$2+\\\\eps$.', '$2\\\\sqrt{T}e^{-\\\\epsilon^2', '$2^d$', '$2n\\\\ln', '$30$', '$500$', '$512', '$66\\\\%$', '$95$\\\\%', '$98.1\\\\%$', '$A', '$A$', '$A_k$', '$C$', '$C(P)$', '$C(P)\\\\log', '$C(s-N)^{1/p}\\\\sqrt{\\\\log', '$C_L$', '$Cs^{1/p}\\\\sqrt{\\\\log', '$D$', '$D_i$', '$G', '$G$', '$G(n,\\\\frac{1}{2})$.', '$G(x)$', '$H\\\\subset', '$I_{\\\\rho_t}(S;A)', '$I_{\\\\rho_t}(S;A)$', '$K$']\n",
            "['$K$-CV,', '$K$-dimensional', '$K$-fold', '$K$-sparse', '$K$th-order', '$K<M\\\\ll', '$KL$', '$L^*_\\\\gamma$', '$L_1$', '$L_1$-norm.', '$L_1$-regularization', '$L_2$', '$L_\\\\infty$-norm', '$L_p$', '$L_p$-nested', '$L_p$-norms', '$L_p$-norms.', '$L_p$-spherically', '$L_p${\\\\em', '$M$', '$M$-estimators', '$N$', '$N$,', '$N(0,\\\\sigma^2I)$,', '$N=s$,', '$N\\\\approx', '$N^2$', '$O(1', '$O(1/\\\\epsilon)$', '$O(1/\\\\epsilon^{2})$', '$O(1/\\\\sqrt{T})$', '$O(1/\\\\sqrt{\\\\epsilon})$', '$O(1/\\\\sqrt{\\\\varepsilon})$.', '$O(1/\\\\sqrt{n})$.', '$O(1/n)$', '$O(1/n)$.', '$O(B\\\\theta', '$O(D^3\\\\log^2', '$O(D^{2+\\\\delta})$', '$O(D^{2})$).', '$O(N^{-0.5+\\\\eps})$', '$O(N^{-0.5})$.', '$O(T^{-1})$.', '$O(T^{-{\\\\gamma}/{d}})$,', '$O(T^{1/2}\\\\log', '$O(T^{2/3}', '$O(\\\\eps)$', '$O(\\\\frac{1}{N}+\\\\exp\\\\{-N\\\\})$', '$O(\\\\frac{1}{N}+\\\\frac{1}{N^2})$', '$O(\\\\frac{\\\\log', '$O(\\\\frac{k^2}{\\\\eps^2}', '$O(\\\\frac{k}{\\\\eps^2}', '$O(\\\\ln', '$O(\\\\log', '$O(\\\\poly(d)\\\\sqrt{T})$', '$O(\\\\sqrt{\\\\eps})$.', '$O(\\\\sqrt{n(\\\\log', '$O(dk^3/\\\\eps^2)$', '$O(k-1)', '$O(m^{1/3}\\\\sqrt{ln', '$O(n', '$O(n)$', '$O(n+', '$O(n\\\\log^2n/\\\\log(2D))$', '$O(n\\\\poly(\\\\log', '$O(n^2)$', '$O(n^3)$', '$O(n^{-\\\\frac{\\\\alpha}{1+\\\\alpha}})$,', '$O(p^2)$', '$O(rn^2)$,', '$O\\\\left(\\\\frac{k}{\\\\eps^2}\\\\left(\\\\min\\\\left(k,', '$R$', '$R$-nearest', '$R^d$.', '$S', '$S$', '$SVM-\\\\theta$', '$S_1$),', '$S_k$', '$S_k$---we', '$S_k$-sparse', '$T', '$T$', '$T$.', '$U(\\\\theta)$', '$U(\\\\theta)$,', '$V$', '$X', '$X$', '$X$.', '$X=x$', '$X\\\\in', '$Y$', '$Y$.', '$Y_T$', '$Y_T$.', '$Z$', '$Z$.', '$\\\\Delta', '$\\\\Delta$']\n",
            "['$\\\\Hilb$', '$\\\\Hilb$.', '$\\\\Hilb$;', '$\\\\LTP$', '$\\\\LowerRateSq', '$\\\\LowerRateSq$', '$\\\\MO$($n^2$)', '$\\\\MO$($np/m$),', '$\\\\MO$($np^2/m$).', '$\\\\Omega', '$\\\\Omega(D\\\\log', '$\\\\Omega(N^2)$', '$\\\\Omega(\\\\sqrt{T})$', '$\\\\Omega(k', '$\\\\Omega(k\\\\log(n-k))$', '$\\\\Omega(p)$', '$\\\\R^d$,', '$\\\\R^d$.', '$\\\\R^n$', '$\\\\R^n$.', '$\\\\R^n_+$.', '$\\\\Real^d$,', '$\\\\Sigma$', '$\\\\Sigma$:', '$\\\\SobM$', '$\\\\Theta$', '$\\\\Theta(\\\\ln', '$\\\\Theta(\\\\sum_{i}D_{i}^{2})$', '$\\\\Theta(k', '$\\\\Theta(n)$', '$\\\\Theta({\\\\sqrt{n}})$', '$\\\\a$-mixing', '$\\\\alpha', '$\\\\alpha$', '$\\\\alpha$-divergence', '$\\\\alpha$-expansion', '$\\\\alpha,\\\\epsilon$,', '$\\\\alpha=0$.', '$\\\\alpha_i$', '$\\\\auc$', '$\\\\beta', '$\\\\beta$-divergences.', '$\\\\beta$.', '$\\\\beta^*$', '$\\\\beta^*$,', '$\\\\beta^*$.', '$\\\\beta^{\\\\star}$', '$\\\\bx$,', '$\\\\cH$', '$\\\\chi^2$', '$\\\\de$', '$\\\\delta$', '$\\\\delta>0$', '$\\\\dim$', '$\\\\dot{\\\\Theta}$', '$\\\\dot{\\\\Theta}$,', '$\\\\ell$', '$\\\\ell_0$', '$\\\\ell_0$-type', '$\\\\ell_1$', '$\\\\ell_1$,', '$\\\\ell_1$-based', '$\\\\ell_1$-norm', '$\\\\ell_1$-norm),', '$\\\\ell_1$-penalized', '$\\\\ell_1$-penalty', '$\\\\ell_1$-regularization', '$\\\\ell_1$-regularized', '$\\\\ell_1$-regularizer).', '$\\\\ell_1$.', '$\\\\ell_1/\\\\ell_q$', '$\\\\ell_2$', '$\\\\ell_2$,', '$\\\\ell_2$-ball', '$\\\\ell_2^2$,', '$\\\\ell_\\\\infty$', '$\\\\ell_\\\\infty$-norms', '$\\\\ellnorm_p$', '$\\\\eps', '$\\\\eps$', '$\\\\eps$,', '$\\\\eps>0$', '$\\\\epsilon', '$\\\\epsilon$', '$\\\\epsilon$-decompositions', '$\\\\epsilon$-descent', '$\\\\epsilon$-optimal', '$\\\\epsilon$-pointwise', '$\\\\epsilon$.', '$\\\\eta$', '$\\\\eta$-function', '$\\\\eta$-function.', '$\\\\exp(-\\\\Theta)$', '$\\\\exp(\\\\cdot)$,', '$\\\\exp(\\\\tilde{O}(1/\\\\gamma))$.', '$\\\\frac{2\\\\gamma{(1-\\\\gamma)^2}\\\\epsilon$-optimal.', '$\\\\frac{2\\\\gamma}{1-\\\\gamma}\\\\epsilon$-optimal,', '$\\\\gamma$', '$\\\\gamma$-approximate', '$\\\\gamma$-discounted']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMYBkIVj8TaS",
        "colab_type": "text"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxwXnb1edrwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word != ',' or word != '.':\n",
        "          new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "          new_words.append(new_word)\n",
        "    return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvSSyr478sfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "  # noise removal\n",
        "  text = re.sub(r'\\bhttps://\\w+.+[^ alt]\\b', 'link', text) #replace url with link\n",
        "  text = re.sub(r'\\~\\\\cite\\{[^}]*\\}','',text) # remove cite in the format of \"~\\cite{DeSaOR16}\"\n",
        "  text = re.sub(r'\\[[^]]*\\]', '', text) # remove between square brackets\n",
        "  text = re.sub(r'\\([^)]*\\)', '', text) # remove between parentheses\n",
        "  text = re.sub(r'\\{[^)]*\\}', '', text) # remove between curly brackets\n",
        "  \n",
        "  # normalization\n",
        "  text = text.lower() # convert to lowercase text\n",
        "  text = re.sub(r'\\-',' ', text) # seperate words like 'video-related'\n",
        "  text = re.sub(r'[^a-zA-Z0-9\\s\\.\\,]', '', text) # remove punctuation \n",
        "  text = re.sub(r'\\.', ' . ', text) # seperate '.' from text\n",
        "  text = re.sub(r'\\,' , ' , ', text) # seperate ',' from text\n",
        "  text = re.sub(r'[-+]?\\d*\\.?\\d+', 'NUMBER', text) # replace numbers with \"NUMBER\"\n",
        " \n",
        "  text = ' '.join(remove_non_ascii(text.split())) # remove non-ascii words\n",
        "  text = re.sub(r'[\\w]*NUMBER[\\w]*', 'NUMBER', text) # replace anyword containing \"NUMBER\" with \"NUMBER\"\n",
        "  \n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ysyMqmZ83sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text.apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVDllxHGqBlb",
        "colab_type": "code",
        "outputId": "35b1b274-afed-4821-ef92-2e0af0d8ac8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print_text(0,text)\n",
        "print_text(10,text)\n",
        "print_text(20, text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "up propagation is an algorithm for inverting and learning neural network generative models sensory input is processed by inverting a model that generates patterns from hidden variables using topdown connections the inversion process is iterative utilizing a negative feedback loop that depends on an error signal propagated by bottomup connections the error signal is also used to learn the generative model from examples the algorithm is benchmarked against principal component analysis in experiments on images of handwritten digits .\n",
            "computational models of visual cortex , and in particular those based on sparse coding , have enjoyed much recent attention . despite this currency , the question of how sparse or how over complete a sparse representation should be , has gone without principled answer . here , we use bayesian model selection methods to address these questions for a sparse coding model based on a student t prior . having validated our methods on toy data , we find that natural images are indeed best modelled by extremely sparse distributions although for the student t prior , the associated optimal basis size is only modestly overcomplete .\n",
            "under natural viewing conditions , human observers shift their gaze to allocate processing resources to subsets of the visual input . many computational models have aimed at predicting such voluntary attentional shifts . although the importance of high level stimulus properties stands undisputed , most models are based on low level features of the input alone . in this study we recorded eye movements of human observers while they viewed photographs of natural scenes . about two thirds of the stimuli contained at least one person . we demonstrate that a combined model of face detection and low level saliency clearly outperforms a low level model in predicting locations humans fixate . this is reflected in our finding fact that observes , even when not instructed to look for anything particular , fixate on a face with a probability of over NUMBER within their first two fixations . remarkably , the models predictive performance in images that do not contain faces is not impaired by spurious face detector responses , which is suggestive of a bottom up mechanism for face detection . in summary , we provide a novel computational approach which combines high level object knowledge with low level features to successfully predict the allocation of attentional resources .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eem9Mwd3YsbO",
        "colab_type": "code",
        "outputId": "f668f5d7-3449-436e-a72d-efa7e42dd1d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "text_list = list(text)\n",
        "corpus = ' '.join(text_list)\n",
        "words = corpus.split()\n",
        "n_words = len(words)\n",
        "unique_words = sorted(list(set(words)))\n",
        "n_unique_words = len(unique_words)\n",
        "print(\"Total number of words:\", n_words)\n",
        "print(\"Total number of unique words: \", n_unique_words)\n",
        "print(unique_words[:100])\n",
        "print(unique_words[100:200])\n",
        "print(unique_words[200:300])\n",
        "print(unique_words[300:400])\n",
        "print(unique_words[400:500])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words: 228231\n",
            "Total number of unique words:  8897\n",
            "[',', '.', 'NUMBER', 'a', 'aaai', 'aalen', 'aberrant', 'abilities', 'ability', 'able', 'abnormalities', 'abound', 'about', 'above', 'abrupt', 'absence', 'absent', 'absolute', 'absolutely', 'absorb', 'absorbed', 'absorbing', 'absorption', 'abstain', 'abstaining', 'abstention', 'abstract', 'abstraction', 'abstractions', 'abstracts', 'abundancy', 'abuse', 'ac', 'accelerate', 'accelerated', 'accelerating', 'acceleration', 'accelerometers', 'accept', 'acceptable', 'acceptance', 'accepted', 'access', 'accessed', 'accessible', 'acclaimed', 'accommodate', 'accommodates', 'accompanied', 'accompanying', 'accomplish', 'accomplished', 'accomplishes', 'accord', 'accordance', 'according', 'accordingly', 'account', 'accounted', 'accounting', 'accounts', 'accp', 'accumulate', 'accumulated', 'accumulation', 'accumulator', 'accuracies', 'accuracy', 'accurate', 'accurately', 'acetylcholine', 'achievable', 'achieve', 'achieved', 'achieves', 'achieving', 'acknowledges', 'acoustic', 'acoustics', 'acquire', 'acquired', 'acquiring', 'acquisition', 'across', 'acs', 'act', 'acterization', 'acting', 'action', 'actions', 'activated', 'activation', 'activations', 'active', 'actively', 'activities', 'activity', 'actor', 'actors', 'acts']\n",
            "['actual', 'actually', 'actuated', 'acyclic', 'ad', 'ada', 'adaboost', 'adap', 'adapt', 'adaptability', 'adaptation', 'adapted', 'adapting', 'adaptive', 'adaptively', 'adaptiveness', 'adaptivity', 'adaptor', 'adapts', 'add', 'added', 'adding', 'addition', 'additional', 'additionally', 'additions', 'additive', 'address', 'addressed', 'addresses', 'addressing', 'adds', 'adequacy', 'adequate', 'adequately', 'adhering', 'adjacency', 'adjacent', 'adjusted', 'adjusting', 'adjustment', 'adjustments', 'adjusts', 'adm', 'administered', 'admira', 'admissible', 'admit', 'admits', 'admixture', 'adni', 'ado', 'adolescent', 'adopt', 'adopted', 'adopting', 'adopts', 'adp', 'adress', 'adresses', 'ads', 'adults', 'advance', 'advanced', 'advancement', 'advances', 'advancing', 'advantage', 'advantageous', 'advantages', 'advent', 'adversarial', 'adversaries', 'adversary', 'adverse', 'advertisement', 'advertisers', 'advertising', 'advice', 'advised', 'advocate', 'advocated', 'aer', 'aesthetic', 'aesthetically', 'afd', 'affairs', 'affect', 'affected', 'affecting', 'affects', 'afferent', 'affine', 'affinities', 'affinity', 'affirmative', 'afforded', 'affords', 'aforementioned', 'aforesaid']\n",
            "['after', 'aftereffects', 'afterwards', 'again', 'against', 'age', 'agenda', 'agendas', 'agent', 'agents', 'agglomerate', 'agglomerative', 'aggregate', 'aggregated', 'aggregating', 'aggregation', 'aggressive', 'aggressively', 'agnostic', 'agnostically', 'ago', 'agorithm', 'agree', 'agreement', 'ahead', 'ahp', 'ai', 'aic', 'aid', 'aids', 'aim', 'aimed', 'aiming', 'aims', 'ais', 'akaike', 'akin', 'al', 'alarm', 'alarms', 'album', 'alcohol', 'alert', 'alexanders', 'algebra', 'algebraic', 'algo', 'algorithm', 'algorithmic', 'algorithmically', 'algorithms', 'aligned', 'aligning', 'alignment', 'alignments', 'aligns', 'alike', 'all', 'allay', 'alleviate', 'alleviated', 'alleviating', 'alligned', 'allocate', 'allocated', 'allocating', 'allocation', 'allow', 'allowed', 'allowing', 'allows', 'almost', 'alone', 'along', 'alongside', 'alpaca', 'alpha', 'alphabet', 'alphabets', 'alphai', 'already', 'also', 'alter', 'alteration', 'altered', 'altering', 'alternate', 'alternately', 'alternates', 'alternating', 'alternation', 'alternations', 'alternative', 'alternatively', 'alternatives', 'although', 'altogether', 'always', 'alzheimer', 'alzheimers']\n",
            "['am', 'amazon', 'ambient', 'ambiguities', 'ambiguity', 'ambiguous', 'ambitious', 'amenable', 'ammar', 'amoebe', 'among', 'amongst', 'amount', 'amounts', 'amp', 'ample', 'amplified', 'amplitude', 'amplitudes', 'an', 'analog', 'analogous', 'analogs', 'analogue', 'analogues', 'analogy', 'analyse', 'analysed', 'analyses', 'analysis', 'analysts', 'analytic', 'analytical', 'analytically', 'analyze', 'analyzed', 'analyzers', 'analyzes', 'analyzing', 'anatomic', 'anatomical', 'anatomically', 'ancestor', 'ancestral', 'anchor', 'anchored', 'anchoring', 'anchors', 'ancient', 'and', 'andor', 'anecdotal', 'anesthesia', 'anesthetized', 'anew', 'angle', 'angles', 'angular', 'animal', 'animals', 'anisotropic', 'anlysis', 'annealed', 'annealing', 'annotate', 'annotated', 'annotating', 'annotation', 'annotations', 'annotator', 'annotators', 'annual', 'anomalies', 'anomalous', 'anomaly', 'anonymize', 'another', 'anothers', 'answer', 'answers', 'ant', 'antagonistic', 'antennal', 'anterior', 'anthropomorphic', 'anticipate', 'anticipated', 'anticipative', 'anticipatory', 'antisense', 'antithetic', 'ants', 'any', 'anything', 'anytime', 'anyway', 'ap', 'apache', 'apart', 'aperture']\n",
            "['apiavi', 'aposteriori', 'apparatus', 'apparent', 'apparently', 'appeal', 'appealing', 'appear', 'appearance', 'appearances', 'appeared', 'appearing', 'appears', 'append', 'appled', 'appliances', 'applica', 'applicability', 'applicable', 'application', 'applications', 'applied', 'applies', 'apply', 'applying', 'apprentices', 'apprenticeship', 'approach', 'approached', 'approaches', 'approaching', 'approachs', 'approporiate', 'appropriate', 'appropriately', 'appropriateness', 'approximate', 'approximated', 'approximately', 'approximates', 'approximating', 'approximation', 'approximationbellman', 'approximations', 'approximator', 'approximators', 'ar', 'arabic', 'arate', 'arbiters', 'arbitrarily', 'arbitrary', 'architecture', 'architectures', 'arcones', 'ard', 'are', 'area', 'areas', 'arguably', 'argue', 'argued', 'argument', 'arguments', 'arise', 'arises', 'arising', 'arithmetic', 'arm', 'armax', 'armed', 'armp', 'arms', 'arora', 'around', 'arow', 'arranged', 'arrangement', 'array', 'arrays', 'arrival', 'arrive', 'arriving', 'art', 'arterial', 'article', 'articles', 'articulated', 'artifact', 'artifacts', 'artificial', 'artificially', 'artists', 'arts', 'ary', 'as', 'ascent', 'asing', 'ask', 'asked']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvLK5QhU0L34",
        "colab_type": "text"
      },
      "source": [
        "# Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sNXXnDEIGSV",
        "colab_type": "text"
      },
      "source": [
        "## Parameters configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQVt7zdjjH_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters configuration\n",
        "SEQUENCE_LENGTH = 100\n",
        "MAX_VOCAB_SIZE = n_unique_words\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyfcHrPpINcK",
        "colab_type": "text"
      },
      "source": [
        "## Create sequences of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lII3wDDPjv9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sequences of words\n",
        "sequences_words = []\n",
        "for i in range(0, n_words - SEQUENCE_LENGTH):\n",
        "\ts = ' '.join(words[i:i+SEQUENCE_LENGTH])\n",
        "\tsequences_words.append(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb3-uI_ZIRbR",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfKBMQAY1a66",
        "colab_type": "code",
        "outputId": "c0f778d8-b84f-45d5-a72f-4f480c5ed333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=False)\n",
        "tokenizer.fit_on_texts(sequences_words)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# convert the sequences into integers\n",
        "sequences = tokenizer.texts_to_sequences(sequences_words)\n",
        "n_sequences = len(sequences)\n",
        "# vocabulary size\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "print(\"Number of unique tokens: \", len(word_index))\n",
        "print('Total number of sequences: %d' % n_sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique tokens:  8897\n",
            "Total number of sequences: 228131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF-Gtu3TIVk-",
        "colab_type": "text"
      },
      "source": [
        "## Create input and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1pTRtLAmNDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create input and output \n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes = vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w9Ggx98E5G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training set and validation set\n",
        "def shuffle_train_test_split(X_all, y_all, shuffle=True, test_percent=20):\n",
        "    \n",
        "    if shuffle:\n",
        "      X_all_shuffled = []\n",
        "      y_all_shuffled = []\n",
        "      for i in np.random.permutation(len(X_all)):\n",
        "          X_all_shuffled.append(X_all[i])\n",
        "          y_all_shuffled.append(y_all[i])\n",
        "    else:\n",
        "      X_all_shuffled = X_all\n",
        "      y_all_shuffled = y_all\n",
        "\n",
        "    split_index = int(len(X_all) * (1.-(test_percent/100.)))\n",
        "    X_train, X_test = X_all_shuffled[:split_index], X_all_shuffled[split_index:]\n",
        "    y_train, y_test = y_all_shuffled[:split_index], y_all_shuffled[split_index:]\n",
        "    \n",
        "    X_train = np.array(X_train)    \n",
        "    y_train = np.array(y_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0tlc5noHHCz",
        "colab_type": "code",
        "outputId": "eab9304d-20d7-479d-d377-683fe0181805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X_train, y_train, X_test, y_test = shuffle_train_test_split(X, y, test_percent=20)\n",
        "\n",
        "print(\"Shape of X training set: \", X_train.shape)\n",
        "print(\"Shape of y training set: \", y_train.shape)\n",
        "print(\"Shape of X test set: \", X_test.shape)\n",
        "print(\"Shape of y test set: \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X training set:  (182504, 99)\n",
            "Shape of y training set:  (182504, 8898)\n",
            "Shape of X test set:  (45627, 99)\n",
            "Shape of y test set:  (45627, 8898)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU9G9d3f7PcA",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwJUxLue7XaN",
        "colab_type": "text"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3u8x8lX5jg3",
        "colab_type": "code",
        "outputId": "a46a70e7-482d-4ca3-97a0-89385c1dae43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=SEQUENCE_LENGTH-1))\n",
        "model.add(LSTM(units=128, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=128)) # the last LSTM layer\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f6543690438>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f6543690d68>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 99, 128)           1138944   \n",
            "_________________________________________________________________\n",
            "unified_lstm_2 (UnifiedLSTM) (None, 99, 128)           131584    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 99, 128)           0         \n",
            "_________________________________________________________________\n",
            "unified_lstm_3 (UnifiedLSTM) (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8898)              1147842   \n",
            "=================================================================\n",
            "Total params: 2,549,954\n",
            "Trainable params: 2,549,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXKGPrQ8-gL5",
        "colab_type": "text"
      },
      "source": [
        "## Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCEmLVPp-hqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaFcd95r-7tD",
        "colab_type": "text"
      },
      "source": [
        "## Define the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gnJCiEb-9C_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = \"model_weights_epoch{epoch:03d}_loss{loss:.4f}_acc{accuracy:.4f}_val_loss{val_loss:.4f}_val_acc{val_accuracy:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
        "callbacks_list = [checkpoint, early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW5XlkgjAuLp",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__8CsMnAPMci",
        "colab_type": "code",
        "outputId": "d10c6e6b-e6ba-4ef5-f645-c33644c38ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          batch_size = BATCH_SIZE, \n",
        "          epochs = EPOCHS, \n",
        "          callbacks = callbacks_list,\n",
        "          validation_data = (X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 182504 samples, validate on 45627 samples\n",
            "Epoch 1/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 6.3895 - accuracy: 0.0789\n",
            "Epoch 00001: loss improved from inf to 6.38965, saving model to model_weights_epoch001_loss6.3896_acc0.0788_val_loss6.8188_val_acc0.0301.hdf5\n",
            "182504/182504 [==============================] - 91s 500us/sample - loss: 6.3896 - accuracy: 0.0788 - val_loss: 6.8188 - val_accuracy: 0.0301\n",
            "Epoch 2/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 5.8639 - accuracy: 0.1270\n",
            "Epoch 00002: loss improved from 6.38965 to 5.86344, saving model to model_weights_epoch002_loss5.8634_acc0.1270_val_loss5.7059_val_acc0.1542.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 5.8634 - accuracy: 0.1270 - val_loss: 5.7059 - val_accuracy: 0.1542\n",
            "Epoch 3/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 5.5221 - accuracy: 0.1618\n",
            "Epoch 00003: loss improved from 5.86344 to 5.52185, saving model to model_weights_epoch003_loss5.5218_acc0.1619_val_loss5.5037_val_acc0.1763.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 5.5218 - accuracy: 0.1619 - val_loss: 5.5037 - val_accuracy: 0.1763\n",
            "Epoch 4/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 5.2827 - accuracy: 0.1806\n",
            "Epoch 00004: loss improved from 5.52185 to 5.28257, saving model to model_weights_epoch004_loss5.2826_acc0.1806_val_loss5.3796_val_acc0.1912.hdf5\n",
            "182504/182504 [==============================] - 90s 495us/sample - loss: 5.2826 - accuracy: 0.1806 - val_loss: 5.3796 - val_accuracy: 0.1912\n",
            "Epoch 5/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 5.0984 - accuracy: 0.1938\n",
            "Epoch 00005: loss improved from 5.28257 to 5.09845, saving model to model_weights_epoch005_loss5.0984_acc0.1938_val_loss5.3119_val_acc0.1978.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 5.0984 - accuracy: 0.1938 - val_loss: 5.3119 - val_accuracy: 0.1978\n",
            "Epoch 6/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.9479 - accuracy: 0.2031\n",
            "Epoch 00006: loss improved from 5.09845 to 4.94770, saving model to model_weights_epoch006_loss4.9477_acc0.2031_val_loss5.2715_val_acc0.2046.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 4.9477 - accuracy: 0.2031 - val_loss: 5.2715 - val_accuracy: 0.2046\n",
            "Epoch 7/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.8187 - accuracy: 0.2118\n",
            "Epoch 00007: loss improved from 4.94770 to 4.81860, saving model to model_weights_epoch007_loss4.8186_acc0.2118_val_loss5.2537_val_acc0.2098.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 4.8186 - accuracy: 0.2118 - val_loss: 5.2537 - val_accuracy: 0.2098\n",
            "Epoch 8/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.7059 - accuracy: 0.2191\n",
            "Epoch 00008: loss improved from 4.81860 to 4.70616, saving model to model_weights_epoch008_loss4.7062_acc0.2191_val_loss5.2431_val_acc0.2134.hdf5\n",
            "182504/182504 [==============================] - 90s 495us/sample - loss: 4.7062 - accuracy: 0.2191 - val_loss: 5.2431 - val_accuracy: 0.2134\n",
            "Epoch 9/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.6048 - accuracy: 0.2248\n",
            "Epoch 00009: loss improved from 4.70616 to 4.60489, saving model to model_weights_epoch009_loss4.6049_acc0.2248_val_loss5.2550_val_acc0.2164.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 4.6049 - accuracy: 0.2248 - val_loss: 5.2550 - val_accuracy: 0.2164\n",
            "Epoch 10/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.5146 - accuracy: 0.2309\n",
            "Epoch 00010: loss improved from 4.60489 to 4.51463, saving model to model_weights_epoch010_loss4.5146_acc0.2309_val_loss5.2782_val_acc0.2190.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 4.5146 - accuracy: 0.2309 - val_loss: 5.2782 - val_accuracy: 0.2190\n",
            "Epoch 11/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.4328 - accuracy: 0.2350\n",
            "Epoch 00011: loss improved from 4.51463 to 4.43269, saving model to model_weights_epoch011_loss4.4327_acc0.2350_val_loss5.2960_val_acc0.2207.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 4.4327 - accuracy: 0.2350 - val_loss: 5.2960 - val_accuracy: 0.2207\n",
            "Epoch 12/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.3538 - accuracy: 0.2393\n",
            "Epoch 00012: loss improved from 4.43269 to 4.35392, saving model to model_weights_epoch012_loss4.3539_acc0.2393_val_loss5.3244_val_acc0.2228.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 4.3539 - accuracy: 0.2393 - val_loss: 5.3244 - val_accuracy: 0.2228\n",
            "Epoch 13/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.2839 - accuracy: 0.2438\n",
            "Epoch 00013: loss improved from 4.35392 to 4.28403, saving model to model_weights_epoch013_loss4.2840_acc0.2438_val_loss5.3577_val_acc0.2252.hdf5\n",
            "182504/182504 [==============================] - 90s 496us/sample - loss: 4.2840 - accuracy: 0.2438 - val_loss: 5.3577 - val_accuracy: 0.2252\n",
            "Epoch 14/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.2177 - accuracy: 0.2479\n",
            "Epoch 00014: loss improved from 4.28403 to 4.21791, saving model to model_weights_epoch014_loss4.2179_acc0.2479_val_loss5.3804_val_acc0.2260.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 4.2179 - accuracy: 0.2479 - val_loss: 5.3804 - val_accuracy: 0.2260\n",
            "Epoch 15/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.1540 - accuracy: 0.2525\n",
            "Epoch 00015: loss improved from 4.21791 to 4.15429, saving model to model_weights_epoch015_loss4.1543_acc0.2524_val_loss5.4044_val_acc0.2264.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 4.1543 - accuracy: 0.2524 - val_loss: 5.4044 - val_accuracy: 0.2264\n",
            "Epoch 16/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.1014 - accuracy: 0.2564\n",
            "Epoch 00016: loss improved from 4.15429 to 4.10130, saving model to model_weights_epoch016_loss4.1013_acc0.2564_val_loss5.4629_val_acc0.2271.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 4.1013 - accuracy: 0.2564 - val_loss: 5.4629 - val_accuracy: 0.2271\n",
            "Epoch 17/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 4.0446 - accuracy: 0.2616\n",
            "Epoch 00017: loss improved from 4.10130 to 4.04459, saving model to model_weights_epoch017_loss4.0446_acc0.2615_val_loss5.4762_val_acc0.2275.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 4.0446 - accuracy: 0.2615 - val_loss: 5.4762 - val_accuracy: 0.2275\n",
            "Epoch 18/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.9971 - accuracy: 0.2654\n",
            "Epoch 00018: loss improved from 4.04459 to 3.99725, saving model to model_weights_epoch018_loss3.9973_acc0.2654_val_loss5.5101_val_acc0.2281.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.9973 - accuracy: 0.2654 - val_loss: 5.5101 - val_accuracy: 0.2281\n",
            "Epoch 19/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.9490 - accuracy: 0.2695\n",
            "Epoch 00019: loss improved from 3.99725 to 3.94895, saving model to model_weights_epoch019_loss3.9490_acc0.2695_val_loss5.5359_val_acc0.2281.hdf5\n",
            "182504/182504 [==============================] - 91s 498us/sample - loss: 3.9490 - accuracy: 0.2695 - val_loss: 5.5359 - val_accuracy: 0.2281\n",
            "Epoch 20/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.9054 - accuracy: 0.2741\n",
            "Epoch 00020: loss improved from 3.94895 to 3.90530, saving model to model_weights_epoch020_loss3.9053_acc0.2741_val_loss5.5665_val_acc0.2285.hdf5\n",
            "182504/182504 [==============================] - 91s 499us/sample - loss: 3.9053 - accuracy: 0.2741 - val_loss: 5.5665 - val_accuracy: 0.2285\n",
            "Epoch 21/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.8640 - accuracy: 0.2776\n",
            "Epoch 00021: loss improved from 3.90530 to 3.86393, saving model to model_weights_epoch021_loss3.8639_acc0.2776_val_loss5.6082_val_acc0.2278.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.8639 - accuracy: 0.2776 - val_loss: 5.6082 - val_accuracy: 0.2278\n",
            "Epoch 22/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.8246 - accuracy: 0.2811\n",
            "Epoch 00022: loss improved from 3.86393 to 3.82478, saving model to model_weights_epoch022_loss3.8248_acc0.2811_val_loss5.6394_val_acc0.2255.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.8248 - accuracy: 0.2811 - val_loss: 5.6394 - val_accuracy: 0.2255\n",
            "Epoch 23/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.7864 - accuracy: 0.2842\n",
            "Epoch 00023: loss improved from 3.82478 to 3.78632, saving model to model_weights_epoch023_loss3.7863_acc0.2842_val_loss5.6659_val_acc0.2273.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.7863 - accuracy: 0.2842 - val_loss: 5.6659 - val_accuracy: 0.2273\n",
            "Epoch 24/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.7489 - accuracy: 0.2890\n",
            "Epoch 00024: loss improved from 3.78632 to 3.74906, saving model to model_weights_epoch024_loss3.7491_acc0.2890_val_loss5.7087_val_acc0.2285.hdf5\n",
            "182504/182504 [==============================] - 91s 498us/sample - loss: 3.7491 - accuracy: 0.2890 - val_loss: 5.7087 - val_accuracy: 0.2285\n",
            "Epoch 25/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.7140 - accuracy: 0.2918\n",
            "Epoch 00025: loss improved from 3.74906 to 3.71415, saving model to model_weights_epoch025_loss3.7141_acc0.2917_val_loss5.7257_val_acc0.2269.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.7141 - accuracy: 0.2917 - val_loss: 5.7257 - val_accuracy: 0.2269\n",
            "Epoch 26/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.6826 - accuracy: 0.2950\n",
            "Epoch 00026: loss improved from 3.71415 to 3.68280, saving model to model_weights_epoch026_loss3.6828_acc0.2950_val_loss5.7618_val_acc0.2269.hdf5\n",
            "182504/182504 [==============================] - 91s 498us/sample - loss: 3.6828 - accuracy: 0.2950 - val_loss: 5.7618 - val_accuracy: 0.2269\n",
            "Epoch 27/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.6542 - accuracy: 0.2988\n",
            "Epoch 00027: loss improved from 3.68280 to 3.65436, saving model to model_weights_epoch027_loss3.6544_acc0.2988_val_loss5.7842_val_acc0.2257.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.6544 - accuracy: 0.2988 - val_loss: 5.7842 - val_accuracy: 0.2257\n",
            "Epoch 28/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.6193 - accuracy: 0.3021\n",
            "Epoch 00028: loss improved from 3.65436 to 3.61925, saving model to model_weights_epoch028_loss3.6193_acc0.3021_val_loss5.8058_val_acc0.2243.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.6193 - accuracy: 0.3021 - val_loss: 5.8058 - val_accuracy: 0.2243\n",
            "Epoch 29/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.5937 - accuracy: 0.3046\n",
            "Epoch 00029: loss improved from 3.61925 to 3.59374, saving model to model_weights_epoch029_loss3.5937_acc0.3046_val_loss5.8394_val_acc0.2266.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.5937 - accuracy: 0.3046 - val_loss: 5.8394 - val_accuracy: 0.2266\n",
            "Epoch 30/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.5624 - accuracy: 0.3075\n",
            "Epoch 00030: loss improved from 3.59374 to 3.56252, saving model to model_weights_epoch030_loss3.5625_acc0.3075_val_loss5.8759_val_acc0.2260.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.5625 - accuracy: 0.3075 - val_loss: 5.8759 - val_accuracy: 0.2260\n",
            "Epoch 31/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.5380 - accuracy: 0.3105\n",
            "Epoch 00031: loss improved from 3.56252 to 3.53808, saving model to model_weights_epoch031_loss3.5381_acc0.3105_val_loss5.8976_val_acc0.2258.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.5381 - accuracy: 0.3105 - val_loss: 5.8976 - val_accuracy: 0.2258\n",
            "Epoch 32/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.5141 - accuracy: 0.3136\n",
            "Epoch 00032: loss improved from 3.53808 to 3.51421, saving model to model_weights_epoch032_loss3.5142_acc0.3136_val_loss5.9233_val_acc0.2254.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.5142 - accuracy: 0.3136 - val_loss: 5.9233 - val_accuracy: 0.2254\n",
            "Epoch 33/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.4874 - accuracy: 0.3172\n",
            "Epoch 00033: loss improved from 3.51421 to 3.48747, saving model to model_weights_epoch033_loss3.4875_acc0.3171_val_loss5.9494_val_acc0.2240.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 3.4875 - accuracy: 0.3171 - val_loss: 5.9494 - val_accuracy: 0.2240\n",
            "Epoch 34/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.4644 - accuracy: 0.3183\n",
            "Epoch 00034: loss improved from 3.48747 to 3.46464, saving model to model_weights_epoch034_loss3.4646_acc0.3183_val_loss5.9878_val_acc0.2251.hdf5\n",
            "182504/182504 [==============================] - 91s 496us/sample - loss: 3.4646 - accuracy: 0.3183 - val_loss: 5.9878 - val_accuracy: 0.2251\n",
            "Epoch 35/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.4421 - accuracy: 0.3222\n",
            "Epoch 00035: loss improved from 3.46464 to 3.44211, saving model to model_weights_epoch035_loss3.4421_acc0.3222_val_loss6.0158_val_acc0.2240.hdf5\n",
            "182504/182504 [==============================] - 90s 495us/sample - loss: 3.4421 - accuracy: 0.3222 - val_loss: 6.0158 - val_accuracy: 0.2240\n",
            "Epoch 36/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.4218 - accuracy: 0.3240\n",
            "Epoch 00036: loss improved from 3.44211 to 3.42184, saving model to model_weights_epoch036_loss3.4218_acc0.3240_val_loss6.0264_val_acc0.2248.hdf5\n",
            "182504/182504 [==============================] - 91s 497us/sample - loss: 3.4218 - accuracy: 0.3240 - val_loss: 6.0264 - val_accuracy: 0.2248\n",
            "Epoch 37/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.3983 - accuracy: 0.3275\n",
            "Epoch 00037: loss improved from 3.42184 to 3.39801, saving model to model_weights_epoch037_loss3.3980_acc0.3275_val_loss6.0504_val_acc0.2239.hdf5\n",
            "182504/182504 [==============================] - 91s 499us/sample - loss: 3.3980 - accuracy: 0.3275 - val_loss: 6.0504 - val_accuracy: 0.2239\n",
            "Epoch 38/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.3765 - accuracy: 0.3286\n",
            "Epoch 00038: loss improved from 3.39801 to 3.37629, saving model to model_weights_epoch038_loss3.3763_acc0.3287_val_loss6.0853_val_acc0.2243.hdf5\n",
            "182504/182504 [==============================] - 91s 499us/sample - loss: 3.3763 - accuracy: 0.3287 - val_loss: 6.0853 - val_accuracy: 0.2243\n",
            "Epoch 39/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.3558 - accuracy: 0.3311\n",
            "Epoch 00039: loss improved from 3.37629 to 3.35571, saving model to model_weights_epoch039_loss3.3557_acc0.3311_val_loss6.1060_val_acc0.2235.hdf5\n",
            "182504/182504 [==============================] - 91s 500us/sample - loss: 3.3557 - accuracy: 0.3311 - val_loss: 6.1060 - val_accuracy: 0.2235\n",
            "Epoch 40/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.3394 - accuracy: 0.3351\n",
            "Epoch 00040: loss improved from 3.35571 to 3.33956, saving model to model_weights_epoch040_loss3.3396_acc0.3350_val_loss6.1365_val_acc0.2239.hdf5\n",
            "182504/182504 [==============================] - 91s 501us/sample - loss: 3.3396 - accuracy: 0.3350 - val_loss: 6.1365 - val_accuracy: 0.2239\n",
            "Epoch 41/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.3200 - accuracy: 0.3351\n",
            "Epoch 00041: loss improved from 3.33956 to 3.32000, saving model to model_weights_epoch041_loss3.3200_acc0.3350_val_loss6.1591_val_acc0.2219.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 3.3200 - accuracy: 0.3350 - val_loss: 6.1591 - val_accuracy: 0.2219\n",
            "Epoch 42/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.2972 - accuracy: 0.3393\n",
            "Epoch 00042: loss improved from 3.32000 to 3.29726, saving model to model_weights_epoch042_loss3.2973_acc0.3393_val_loss6.1777_val_acc0.2219.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 3.2973 - accuracy: 0.3393 - val_loss: 6.1777 - val_accuracy: 0.2219\n",
            "Epoch 43/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.2799 - accuracy: 0.3420\n",
            "Epoch 00043: loss improved from 3.29726 to 3.28003, saving model to model_weights_epoch043_loss3.2800_acc0.3420_val_loss6.1847_val_acc0.2205.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.2800 - accuracy: 0.3420 - val_loss: 6.1847 - val_accuracy: 0.2205\n",
            "Epoch 44/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.2624 - accuracy: 0.3421\n",
            "Epoch 00044: loss improved from 3.28003 to 3.26239, saving model to model_weights_epoch044_loss3.2624_acc0.3421_val_loss6.2315_val_acc0.2205.hdf5\n",
            "182504/182504 [==============================] - 93s 508us/sample - loss: 3.2624 - accuracy: 0.3421 - val_loss: 6.2315 - val_accuracy: 0.2205\n",
            "Epoch 45/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.2472 - accuracy: 0.3440\n",
            "Epoch 00045: loss improved from 3.26239 to 3.24738, saving model to model_weights_epoch045_loss3.2474_acc0.3440_val_loss6.2301_val_acc0.2207.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.2474 - accuracy: 0.3440 - val_loss: 6.2301 - val_accuracy: 0.2207\n",
            "Epoch 46/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.2271 - accuracy: 0.3469\n",
            "Epoch 00046: loss improved from 3.24738 to 3.22709, saving model to model_weights_epoch046_loss3.2271_acc0.3469_val_loss6.2814_val_acc0.2210.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.2271 - accuracy: 0.3469 - val_loss: 6.2814 - val_accuracy: 0.2210\n",
            "Epoch 47/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.2134 - accuracy: 0.3488\n",
            "Epoch 00047: loss improved from 3.22709 to 3.21338, saving model to model_weights_epoch047_loss3.2134_acc0.3488_val_loss6.3107_val_acc0.2220.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.2134 - accuracy: 0.3488 - val_loss: 6.3107 - val_accuracy: 0.2220\n",
            "Epoch 48/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.1990 - accuracy: 0.3504\n",
            "Epoch 00048: loss improved from 3.21338 to 3.19897, saving model to model_weights_epoch048_loss3.1990_acc0.3504_val_loss6.3057_val_acc0.2202.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.1990 - accuracy: 0.3504 - val_loss: 6.3057 - val_accuracy: 0.2202\n",
            "Epoch 49/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.1832 - accuracy: 0.3520\n",
            "Epoch 00049: loss improved from 3.19897 to 3.18337, saving model to model_weights_epoch049_loss3.1834_acc0.3520_val_loss6.3319_val_acc0.2191.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 3.1834 - accuracy: 0.3520 - val_loss: 6.3319 - val_accuracy: 0.2191\n",
            "Epoch 50/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.1646 - accuracy: 0.3547\n",
            "Epoch 00050: loss improved from 3.18337 to 3.16462, saving model to model_weights_epoch050_loss3.1646_acc0.3547_val_loss6.3719_val_acc0.2208.hdf5\n",
            "182504/182504 [==============================] - 92s 504us/sample - loss: 3.1646 - accuracy: 0.3547 - val_loss: 6.3719 - val_accuracy: 0.2208\n",
            "Epoch 51/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.1552 - accuracy: 0.3557\n",
            "Epoch 00051: loss improved from 3.16462 to 3.15520, saving model to model_weights_epoch051_loss3.1552_acc0.3557_val_loss6.3851_val_acc0.2196.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.1552 - accuracy: 0.3557 - val_loss: 6.3851 - val_accuracy: 0.2196\n",
            "Epoch 52/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.1371 - accuracy: 0.3578\n",
            "Epoch 00052: loss improved from 3.15520 to 3.13726, saving model to model_weights_epoch052_loss3.1373_acc0.3577_val_loss6.3976_val_acc0.2198.hdf5\n",
            "182504/182504 [==============================] - 92s 504us/sample - loss: 3.1373 - accuracy: 0.3577 - val_loss: 6.3976 - val_accuracy: 0.2198\n",
            "Epoch 53/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.1238 - accuracy: 0.3588\n",
            "Epoch 00053: loss improved from 3.13726 to 3.12375, saving model to model_weights_epoch053_loss3.1237_acc0.3589_val_loss6.4417_val_acc0.2199.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.1237 - accuracy: 0.3589 - val_loss: 6.4417 - val_accuracy: 0.2199\n",
            "Epoch 54/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.1100 - accuracy: 0.3611\n",
            "Epoch 00054: loss improved from 3.12375 to 3.11008, saving model to model_weights_epoch054_loss3.1101_acc0.3611_val_loss6.4541_val_acc0.2204.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 3.1101 - accuracy: 0.3611 - val_loss: 6.4541 - val_accuracy: 0.2204\n",
            "Epoch 55/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.0972 - accuracy: 0.3631\n",
            "Epoch 00055: loss improved from 3.11008 to 3.09719, saving model to model_weights_epoch055_loss3.0972_acc0.3631_val_loss6.4691_val_acc0.2191.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.0972 - accuracy: 0.3631 - val_loss: 6.4691 - val_accuracy: 0.2191\n",
            "Epoch 56/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.0868 - accuracy: 0.3630\n",
            "Epoch 00056: loss improved from 3.09719 to 3.08695, saving model to model_weights_epoch056_loss3.0870_acc0.3630_val_loss6.4816_val_acc0.2186.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.0870 - accuracy: 0.3630 - val_loss: 6.4816 - val_accuracy: 0.2186\n",
            "Epoch 57/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.0674 - accuracy: 0.3653\n",
            "Epoch 00057: loss improved from 3.08695 to 3.06742, saving model to model_weights_epoch057_loss3.0674_acc0.3653_val_loss6.5116_val_acc0.2186.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 3.0674 - accuracy: 0.3653 - val_loss: 6.5116 - val_accuracy: 0.2186\n",
            "Epoch 58/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.0557 - accuracy: 0.3675\n",
            "Epoch 00058: loss improved from 3.06742 to 3.05578, saving model to model_weights_epoch058_loss3.0558_acc0.3674_val_loss6.5355_val_acc0.2190.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.0558 - accuracy: 0.3674 - val_loss: 6.5355 - val_accuracy: 0.2190\n",
            "Epoch 59/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.0494 - accuracy: 0.3693\n",
            "Epoch 00059: loss improved from 3.05578 to 3.04946, saving model to model_weights_epoch059_loss3.0495_acc0.3693_val_loss6.5732_val_acc0.2207.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.0495 - accuracy: 0.3693 - val_loss: 6.5732 - val_accuracy: 0.2207\n",
            "Epoch 60/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.0291 - accuracy: 0.3699\n",
            "Epoch 00060: loss improved from 3.04946 to 3.02900, saving model to model_weights_epoch060_loss3.0290_acc0.3699_val_loss6.5787_val_acc0.2196.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 3.0290 - accuracy: 0.3699 - val_loss: 6.5787 - val_accuracy: 0.2196\n",
            "Epoch 61/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.0189 - accuracy: 0.3726\n",
            "Epoch 00061: loss improved from 3.02900 to 3.01897, saving model to model_weights_epoch061_loss3.0190_acc0.3726_val_loss6.6112_val_acc0.2182.hdf5\n",
            "182504/182504 [==============================] - 93s 507us/sample - loss: 3.0190 - accuracy: 0.3726 - val_loss: 6.6112 - val_accuracy: 0.2182\n",
            "Epoch 62/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 3.0114 - accuracy: 0.3736\n",
            "Epoch 00062: loss improved from 3.01897 to 3.01138, saving model to model_weights_epoch062_loss3.0114_acc0.3736_val_loss6.6245_val_acc0.2173.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 3.0114 - accuracy: 0.3736 - val_loss: 6.6245 - val_accuracy: 0.2173\n",
            "Epoch 63/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9947 - accuracy: 0.3746\n",
            "Epoch 00063: loss improved from 3.01138 to 2.99452, saving model to model_weights_epoch063_loss2.9945_acc0.3746_val_loss6.6104_val_acc0.2179.hdf5\n",
            "182504/182504 [==============================] - 93s 507us/sample - loss: 2.9945 - accuracy: 0.3746 - val_loss: 6.6104 - val_accuracy: 0.2179\n",
            "Epoch 64/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9887 - accuracy: 0.3751\n",
            "Epoch 00064: loss improved from 2.99452 to 2.98861, saving model to model_weights_epoch064_loss2.9886_acc0.3751_val_loss6.6645_val_acc0.2160.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.9886 - accuracy: 0.3751 - val_loss: 6.6645 - val_accuracy: 0.2160\n",
            "Epoch 65/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9788 - accuracy: 0.3765\n",
            "Epoch 00065: loss improved from 2.98861 to 2.97883, saving model to model_weights_epoch065_loss2.9788_acc0.3764_val_loss6.6600_val_acc0.2164.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.9788 - accuracy: 0.3764 - val_loss: 6.6600 - val_accuracy: 0.2164\n",
            "Epoch 66/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9651 - accuracy: 0.3786\n",
            "Epoch 00066: loss improved from 2.97883 to 2.96522, saving model to model_weights_epoch066_loss2.9652_acc0.3786_val_loss6.7070_val_acc0.2166.hdf5\n",
            "182504/182504 [==============================] - 92s 507us/sample - loss: 2.9652 - accuracy: 0.3786 - val_loss: 6.7070 - val_accuracy: 0.2166\n",
            "Epoch 67/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9574 - accuracy: 0.3792\n",
            "Epoch 00067: loss improved from 2.96522 to 2.95735, saving model to model_weights_epoch067_loss2.9574_acc0.3792_val_loss6.7037_val_acc0.2172.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.9574 - accuracy: 0.3792 - val_loss: 6.7037 - val_accuracy: 0.2172\n",
            "Epoch 68/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9420 - accuracy: 0.3818\n",
            "Epoch 00068: loss improved from 2.95735 to 2.94211, saving model to model_weights_epoch068_loss2.9421_acc0.3818_val_loss6.7279_val_acc0.2165.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.9421 - accuracy: 0.3818 - val_loss: 6.7279 - val_accuracy: 0.2165\n",
            "Epoch 69/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9336 - accuracy: 0.3830\n",
            "Epoch 00069: loss improved from 2.94211 to 2.93403, saving model to model_weights_epoch069_loss2.9340_acc0.3830_val_loss6.7392_val_acc0.2164.hdf5\n",
            "182504/182504 [==============================] - 93s 507us/sample - loss: 2.9340 - accuracy: 0.3830 - val_loss: 6.7392 - val_accuracy: 0.2164\n",
            "Epoch 70/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9245 - accuracy: 0.3831\n",
            "Epoch 00070: loss improved from 2.93403 to 2.92455, saving model to model_weights_epoch070_loss2.9245_acc0.3831_val_loss6.7752_val_acc0.2143.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.9245 - accuracy: 0.3831 - val_loss: 6.7752 - val_accuracy: 0.2143\n",
            "Epoch 71/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9151 - accuracy: 0.3860\n",
            "Epoch 00071: loss improved from 2.92455 to 2.91506, saving model to model_weights_epoch071_loss2.9151_acc0.3860_val_loss6.7551_val_acc0.2170.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.9151 - accuracy: 0.3860 - val_loss: 6.7551 - val_accuracy: 0.2170\n",
            "Epoch 72/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.9048 - accuracy: 0.3860\n",
            "Epoch 00072: loss improved from 2.91506 to 2.90483, saving model to model_weights_epoch072_loss2.9048_acc0.3860_val_loss6.7805_val_acc0.2146.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.9048 - accuracy: 0.3860 - val_loss: 6.7805 - val_accuracy: 0.2146\n",
            "Epoch 73/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8936 - accuracy: 0.3873\n",
            "Epoch 00073: loss improved from 2.90483 to 2.89345, saving model to model_weights_epoch073_loss2.8934_acc0.3873_val_loss6.8383_val_acc0.2156.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.8934 - accuracy: 0.3873 - val_loss: 6.8383 - val_accuracy: 0.2156\n",
            "Epoch 74/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8841 - accuracy: 0.3895\n",
            "Epoch 00074: loss improved from 2.89345 to 2.88437, saving model to model_weights_epoch074_loss2.8844_acc0.3895_val_loss6.8322_val_acc0.2157.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.8844 - accuracy: 0.3895 - val_loss: 6.8322 - val_accuracy: 0.2157\n",
            "Epoch 75/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8728 - accuracy: 0.3911\n",
            "Epoch 00075: loss improved from 2.88437 to 2.87296, saving model to model_weights_epoch075_loss2.8730_acc0.3911_val_loss6.8711_val_acc0.2154.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.8730 - accuracy: 0.3911 - val_loss: 6.8711 - val_accuracy: 0.2154\n",
            "Epoch 76/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8656 - accuracy: 0.3916\n",
            "Epoch 00076: loss improved from 2.87296 to 2.86564, saving model to model_weights_epoch076_loss2.8656_acc0.3916_val_loss6.8852_val_acc0.2165.hdf5\n",
            "182504/182504 [==============================] - 92s 504us/sample - loss: 2.8656 - accuracy: 0.3916 - val_loss: 6.8852 - val_accuracy: 0.2165\n",
            "Epoch 77/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8580 - accuracy: 0.3928\n",
            "Epoch 00077: loss improved from 2.86564 to 2.85800, saving model to model_weights_epoch077_loss2.8580_acc0.3928_val_loss6.8915_val_acc0.2147.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.8580 - accuracy: 0.3928 - val_loss: 6.8915 - val_accuracy: 0.2147\n",
            "Epoch 78/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8500 - accuracy: 0.3949\n",
            "Epoch 00078: loss improved from 2.85800 to 2.85006, saving model to model_weights_epoch078_loss2.8501_acc0.3949_val_loss6.9134_val_acc0.2137.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.8501 - accuracy: 0.3949 - val_loss: 6.9134 - val_accuracy: 0.2137\n",
            "Epoch 79/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8367 - accuracy: 0.3945\n",
            "Epoch 00079: loss improved from 2.85006 to 2.83649, saving model to model_weights_epoch079_loss2.8365_acc0.3946_val_loss6.9359_val_acc0.2139.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.8365 - accuracy: 0.3946 - val_loss: 6.9359 - val_accuracy: 0.2139\n",
            "Epoch 80/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8323 - accuracy: 0.3962\n",
            "Epoch 00080: loss improved from 2.83649 to 2.83233, saving model to model_weights_epoch080_loss2.8323_acc0.3962_val_loss6.9556_val_acc0.2153.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.8323 - accuracy: 0.3962 - val_loss: 6.9556 - val_accuracy: 0.2153\n",
            "Epoch 81/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8265 - accuracy: 0.3958\n",
            "Epoch 00081: loss improved from 2.83233 to 2.82642, saving model to model_weights_epoch081_loss2.8264_acc0.3958_val_loss6.9631_val_acc0.2141.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.8264 - accuracy: 0.3958 - val_loss: 6.9631 - val_accuracy: 0.2141\n",
            "Epoch 82/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8121 - accuracy: 0.3990\n",
            "Epoch 00082: loss improved from 2.82642 to 2.81228, saving model to model_weights_epoch082_loss2.8123_acc0.3990_val_loss6.9713_val_acc0.2144.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.8123 - accuracy: 0.3990 - val_loss: 6.9713 - val_accuracy: 0.2144\n",
            "Epoch 83/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.8080 - accuracy: 0.4002\n",
            "Epoch 00083: loss improved from 2.81228 to 2.80798, saving model to model_weights_epoch083_loss2.8080_acc0.4002_val_loss6.9929_val_acc0.2126.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.8080 - accuracy: 0.4002 - val_loss: 6.9929 - val_accuracy: 0.2126\n",
            "Epoch 84/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7946 - accuracy: 0.4003\n",
            "Epoch 00084: loss improved from 2.80798 to 2.79480, saving model to model_weights_epoch084_loss2.7948_acc0.4003_val_loss6.9988_val_acc0.2124.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.7948 - accuracy: 0.4003 - val_loss: 6.9988 - val_accuracy: 0.2124\n",
            "Epoch 85/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7879 - accuracy: 0.4027\n",
            "Epoch 00085: loss improved from 2.79480 to 2.78790, saving model to model_weights_epoch085_loss2.7879_acc0.4027_val_loss7.0218_val_acc0.2123.hdf5\n",
            "182504/182504 [==============================] - 92s 505us/sample - loss: 2.7879 - accuracy: 0.4027 - val_loss: 7.0218 - val_accuracy: 0.2123\n",
            "Epoch 86/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7837 - accuracy: 0.4021\n",
            "Epoch 00086: loss improved from 2.78790 to 2.78395, saving model to model_weights_epoch086_loss2.7840_acc0.4020_val_loss7.0526_val_acc0.2150.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.7840 - accuracy: 0.4020 - val_loss: 7.0526 - val_accuracy: 0.2150\n",
            "Epoch 87/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7766 - accuracy: 0.4037\n",
            "Epoch 00087: loss improved from 2.78395 to 2.77680, saving model to model_weights_epoch087_loss2.7768_acc0.4036_val_loss7.0403_val_acc0.2152.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.7768 - accuracy: 0.4036 - val_loss: 7.0403 - val_accuracy: 0.2152\n",
            "Epoch 88/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7723 - accuracy: 0.4040\n",
            "Epoch 00088: loss improved from 2.77680 to 2.77237, saving model to model_weights_epoch088_loss2.7724_acc0.4040_val_loss7.0591_val_acc0.2128.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.7724 - accuracy: 0.4040 - val_loss: 7.0591 - val_accuracy: 0.2128\n",
            "Epoch 89/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7605 - accuracy: 0.4058\n",
            "Epoch 00089: loss improved from 2.77237 to 2.76047, saving model to model_weights_epoch089_loss2.7605_acc0.4058_val_loss7.0620_val_acc0.2137.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.7605 - accuracy: 0.4058 - val_loss: 7.0620 - val_accuracy: 0.2137\n",
            "Epoch 90/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7476 - accuracy: 0.4074\n",
            "Epoch 00090: loss improved from 2.76047 to 2.74792, saving model to model_weights_epoch090_loss2.7479_acc0.4073_val_loss7.0970_val_acc0.2128.hdf5\n",
            "182504/182504 [==============================] - 93s 508us/sample - loss: 2.7479 - accuracy: 0.4073 - val_loss: 7.0970 - val_accuracy: 0.2128\n",
            "Epoch 91/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7472 - accuracy: 0.4075\n",
            "Epoch 00091: loss improved from 2.74792 to 2.74712, saving model to model_weights_epoch091_loss2.7471_acc0.4075_val_loss7.0973_val_acc0.2120.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.7471 - accuracy: 0.4075 - val_loss: 7.0973 - val_accuracy: 0.2120\n",
            "Epoch 92/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7349 - accuracy: 0.4099\n",
            "Epoch 00092: loss improved from 2.74712 to 2.73508, saving model to model_weights_epoch092_loss2.7351_acc0.4099_val_loss7.1370_val_acc0.2124.hdf5\n",
            "182504/182504 [==============================] - 93s 508us/sample - loss: 2.7351 - accuracy: 0.4099 - val_loss: 7.1370 - val_accuracy: 0.2124\n",
            "Epoch 93/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7299 - accuracy: 0.4102\n",
            "Epoch 00093: loss improved from 2.73508 to 2.72979, saving model to model_weights_epoch093_loss2.7298_acc0.4102_val_loss7.1453_val_acc0.2126.hdf5\n",
            "182504/182504 [==============================] - 92s 507us/sample - loss: 2.7298 - accuracy: 0.4102 - val_loss: 7.1453 - val_accuracy: 0.2126\n",
            "Epoch 94/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7266 - accuracy: 0.4104\n",
            "Epoch 00094: loss improved from 2.72979 to 2.72659, saving model to model_weights_epoch094_loss2.7266_acc0.4104_val_loss7.1625_val_acc0.2118.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.7266 - accuracy: 0.4104 - val_loss: 7.1625 - val_accuracy: 0.2118\n",
            "Epoch 95/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7207 - accuracy: 0.4102\n",
            "Epoch 00095: loss improved from 2.72659 to 2.72041, saving model to model_weights_epoch095_loss2.7204_acc0.4103_val_loss7.1751_val_acc0.2117.hdf5\n",
            "182504/182504 [==============================] - 92s 507us/sample - loss: 2.7204 - accuracy: 0.4103 - val_loss: 7.1751 - val_accuracy: 0.2117\n",
            "Epoch 96/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7088 - accuracy: 0.4131\n",
            "Epoch 00096: loss improved from 2.72041 to 2.70882, saving model to model_weights_epoch096_loss2.7088_acc0.4131_val_loss7.1875_val_acc0.2115.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.7088 - accuracy: 0.4131 - val_loss: 7.1875 - val_accuracy: 0.2115\n",
            "Epoch 97/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7017 - accuracy: 0.4130\n",
            "Epoch 00097: loss improved from 2.70882 to 2.70154, saving model to model_weights_epoch097_loss2.7015_acc0.4130_val_loss7.1851_val_acc0.2117.hdf5\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.7015 - accuracy: 0.4130 - val_loss: 7.1851 - val_accuracy: 0.2117\n",
            "Epoch 98/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.7005 - accuracy: 0.4133\n",
            "Epoch 00098: loss improved from 2.70154 to 2.70071, saving model to model_weights_epoch098_loss2.7007_acc0.4132_val_loss7.2060_val_acc0.2120.hdf5\n",
            "182504/182504 [==============================] - 93s 509us/sample - loss: 2.7007 - accuracy: 0.4132 - val_loss: 7.2060 - val_accuracy: 0.2120\n",
            "Epoch 99/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.6873 - accuracy: 0.4160\n",
            "Epoch 00099: loss improved from 2.70071 to 2.68750, saving model to model_weights_epoch099_loss2.6875_acc0.4159_val_loss7.2186_val_acc0.2121.hdf5\n",
            "182504/182504 [==============================] - 93s 509us/sample - loss: 2.6875 - accuracy: 0.4159 - val_loss: 7.2186 - val_accuracy: 0.2121\n",
            "Epoch 100/100\n",
            "182400/182504 [============================>.] - ETA: 0s - loss: 2.6891 - accuracy: 0.4153\n",
            "Epoch 00100: loss did not improve from 2.68750\n",
            "182504/182504 [==============================] - 92s 506us/sample - loss: 2.6891 - accuracy: 0.4153 - val_loss: 7.2407 - val_accuracy: 0.2110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f653f37a320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seN4D8PfESAX",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kFsZo9p66MS",
        "colab_type": "code",
        "outputId": "0dd14fbe-efd7-4863-e40a-379f0731ba8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# Plot train and validation curves\n",
        "fig = plt.figure()\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeXhc5Xnw/+89o1k00mhfbEm2ZWxj\nzGqDMRAggQBlJxBSkiZOszWmTduQBd6QviEJXd6mv7SUrCSBkGaDhEBIaDCJIYFsrLYxYLDBuyXZ\nkrXvMxrN3L8/niN5ZMu2jCWNpLk/13WumTnrM0dH555nOc8jqooxxhgz1fgynQBjjDFmNBagjDHG\nTEkWoIwxxkxJFqCMMcZMSRagjDHGTEkWoIwxxkxJFqCMeZNE5H9E5F/HuO5OEbl4otNkzExiAcoY\nY8yUZAHKmCwnIjmZToMxo7EAZWY0r2jtFhF5WUR6ReS7IlIpIo+JSLeIPCEixWnrXyMir4pIh4g8\nJSJL0pYtE5H13nY/BcIHHOsqEdngbfu0iJw6xjReKSIvikiXiNSJyBcPWH6et78Ob/kHvfm5IvJf\nIrJLRDpF5E/evAtEpH6U83Cx9/6LIvKgiPxIRLqAD4rIChF5xjvGXhH5uogE07Y/SUQeF5E2EWkS\nkX8SkVki0icipWnrnS4izSISGMt3N+ZwLECZbHA9cAlwPHA18BjwT0A57n/g4wAicjxwP/AJb9lq\n4H9FJOjdrH8B/BAoAX7m7Rdv22XAvcCNQCnwbeAREQmNIX29wF8DRcCVwN+JyLXefud56f2al6al\nwAZvu/8EzgDe4qXp/wCpMZ6TdwAPesf8MZAEPgmUAecAFwEf89IQBZ4Afg1UAQuB36pqI/AUcEPa\nft8P/ERVE2NMhzGHZAHKZIOvqWqTqjYAfwSeU9UXVTUGPAws89Z7N/Coqj7u3WD/E8jFBYCzgQBw\np6omVPVB4IW0Y6wCvq2qz6lqUlW/D8S97Q5LVZ9S1VdUNaWqL+OC5Nu8xe8FnlDV+73jtqrqBhHx\nAR8GblLVBu+YT6tqfIzn5BlV/YV3zH5VXaeqz6rqoKruxAXYoTRcBTSq6n+pakxVu1X1OW/Z94GV\nACLiB/4KF8SNOWYWoEw2aEp73z/K53zvfRWwa2iBqqaAOqDaW9agI3tX3pX2fh7waa+IrENEOoA5\n3naHJSJniciTXtFYJ/C3uJwM3j62jbJZGa6IcbRlY1F3QBqOF5FfiUijV+z3/8aQBoBfAieKyHxc\nLrVTVZ9/k2kyZgQLUMbstwcXaAAQEcHdnBuAvUC1N2/I3LT3dcC/qWpR2hRR1fvHcNz7gEeAOapa\nCHwLGDpOHbBglG1agNghlvUCkbTv4ccVD6Y7cBiDu4DNwCJVLcAVgaan4bjREu7lQh/A5aLej+We\nzDiyAGXMfg8AV4rIRV4l/6dxxXRPA88Ag8DHRSQgIu8EVqRtezfwt15uSEQkz2v8EB3DcaNAm6rG\nRGQFrlhvyI+Bi0XkBhHJEZFSEVnq5e7uBe4QkSoR8YvIOV6d1xtA2Dt+APgccKS6sCjQBfSIyAnA\n36Ut+xUwW0Q+ISIhEYmKyFlpy38AfBC4BgtQZhxZgDLGo6qv43ICX8PlUK4GrlbVAVUdAN6JuxG3\n4eqrfp627Vrgo8DXgXZgq7fuWHwM+GcR6QY+jwuUQ/vdDVyBC5ZtuAYSp3mLbwZewdWFtQH/AfhU\ntdPb5z243F8vMKJV3yhuxgXGblyw/WlaGrpxxXdXA43AFuDCtOV/xjXOWK+q6cWexhwTsQELjTHH\nSkR+B9ynqvdkOi1m5rAAZYw5JiJyJvA4rg6tO9PpMTOHFfEZY940Efk+7hmpT1hwMuPNclDGGGOm\nJMtBGWOMmZKmXSeRZWVlWltbm+lkGGOMGSfr1q1rUdUDn9WbfgGqtraWtWvXZjoZxhhjxomIjPp4\nghXxGWOMmZKmXQ7KGGPM+FFVmnvi9MaT+AQEQQSSKSWpymBS2dPZz47mXna09NLaGyeU4ycc8BHK\n8XPtsmqWzimakLRNaIASkcuArwB+4B5V/dIh1rse1/X/md4T+cYYY0ahqsQSKQZTKVIpGEylaOyK\nUdfWT317H809cQaTymAyxWBKSamSSkFKFcV1sOgTIZFMsaO1l237euiKDY7p2AXhHMqjIQaSKWKJ\nFLFEkmVzi6ZfgPI6qPwGrouUeuAFEXlEVV87YL0ocBPw3MF7McaYmUFVaesdoKM/QW7AT27ATzDH\nR2d/gpaeOC09cbpjgwwmlUTS3fybe+Ls64rT1B2npTtOW+8Abb0DDCQPPexX0O8j4Bdy/D5yfILP\nJ/hF8Hld/yqgCn6fMLckwjVLq1hQnk9RJIAqpNSl1e8T/D7BJ8KswjDHleVRkhdkZH/JE2sic1Ar\ngK2quh1ARH6CGyTttQPW+xdcH2K3TGBajDFm3PXEB3m9sZvXG7tp6orR2Z+gsz9BT3wQVfVu+Epj\nV5y6tj564mPLqQzx+4SKaIiKaIjZhWFOqiqgJD9IYW6AgM/nBR8oj4aZWxJhbkmEwsjMGcx4IgNU\nNSPHnKkH0ntARkROx3WP8qiIHDJAicgq3IBwzJ0791CrGWPMYanqcPFUlxdMOvoSNHXF2NPRz57O\nGF2xBDlergOBjj6Xw2ntGSA+mCTg95HjF5JJZU9nbMT+o+EciiIB8oI5+MTV5YjArIIQZ80vYW5J\nhJK8ILFEkv5EkvhgisLcAGX5Icryg0TDAZcDyhGCfh/FkSA+3+TlWKaajDWS8EYEvYMx9Pisqt8B\nvgOwfPly6/rCGAO4gNM7kKSjb4COvgT7umPUt/fT0O6CTXN3jJaeAVp64vTFk4ctGgMozQtSGAmQ\n8hoIpFJQkBugLD/IwvJ8wkE/g8kUiaS7DS0oz+OEWQUsnhWlqigXfxYHk4kwkQGqATfY25Aab96Q\nKHAy8JRXpjkLeERErrGGEsZkj0QyRUN7Py09cbpiQ0VkyeEissGUUtfWx7bmHrY09dDcs39Ue1Ul\nNcpP1qDfx+yiMBXREIsq8jn7uBLyQwGCOT5C3lSQG6DQmyoLwswuDBMO+Cfxm5sjmcgA9QKwyBsK\nugF4D2kDsXlj1gwNKY2IPAXcbMHJmOlvMJmisz9BW+8Aezq94rOOftr7BoglUvQnknTHBtnd2kt9\nez+Do0WZNJGgn4UV+bxlYSmzC8MI+3MqBbk5FOUGKYoEKIuGqCnKpSw/lNVFYzPFhAUoVR0UkX8A\nfoNrZn6vqr4qIv8MrFXVRybq2MaYYzf0fMz+518G6IkP0hMbpCc+SHdskJ54gt54kljCFZ8NDKbo\njQ+O2mzZ7xMKcwPkBvyEAj7ygjmcVFXIlafOprY0j4qC8HCOJi/ox+eT4SbRhbkBCzhZaELroFR1\nNbD6gHmfP8S6F0xkWowxLui09AzQ4OVo9nT009gZo6k7TlOna4UWG0wST6TojiXoHUiO2D7HJ0TD\nOeSFcoiGA+SH/JTmB4ebTAf9PiJBP0WRIMWRAMV5QWYX5lJdnEtlNESO3zqvMWNnPUkYM40NPVtT\n397P3s5+9nbGaOyM0d43ALheAVKq7OuOU9feR0N7P/HBkQ0FwgEfswrCVBaEqS2LEA74CeX4iARz\nmFca4bjyfI4ry6M8GiKU45vU52BMdrMAZcwUMtRLQHcsQVdskM7+/U2g93bGaOsdoKs/QVfMq9/p\niNGfGJnLCfp9FOcF8IkwNNxbeTTE4sooF51QQXVRLtXFEfdalEtBbo4FHTMlWYAyZpIMNYlu6Y7T\n2hunuXvAe42zu7WP7S2urqezPzHq9uGAj7L8EIW5AQrCARZVRLlgcQU1xbnUFEeoKgozuzCX4kjA\nAo6ZESxAGTNOhorbtu7rYVtzLztbe70it34au2I0d8eJJUZ/Dmd2YZj5ZXlcfdpsqopyKQgHiIZz\nKMgNUBkNU1XkGhBY4DHZxAKUMUfQ0TfAtuYetnut2dp6B1wHnOqe4WnpibuGBl3xEV3ZhHJ8zC50\ndTvL5hRTEQ1RFg1Rnh+iND/o9R4QoiQvSDDHGg8YcyALUCbrxRJJXt3TRXdsf9Faa88Aa3e18fyO\nNrY19w7Pz/EJJXnB4U40/T6hLD/I8ZVRzl9UTk1xLgsr8llYkU9VYa41jTbmGFiAMllhqPFBY1eM\n3W197G7rY9u+Hl6s6+C1PZ3DXdeki4ZzWD6vmOvPqGHJrAJqy/KoKc4lYE2ljZkUFqDMjBEfTNLc\nHWdHSy8bG7rYuKeT1xu76egboLM/cVAQyg34ObWmkI+cdxzL5hZRHg0NL8sP5bCwPN9yQMZk0JgC\nlIj8HPgu8JiqHr63RWMmkKrSn0hS397Pht0dvFjXzkt1nezp7Kejb2TrtzkluSyZVUBZtGS45VtZ\nfpB5pXnMK41Qbt3hGDOljTUH9U3gQ8BXReRnwPdU9fWJS5bJdl2xBK83drOxoZNXGjp5bU8X+7rj\ndPUnRvTbVhDO4bQ5RZw+r4jKaJiKghBziiOcVFU4o8bFMSYbjSlAqeoTwBMiUgj8lfe+Drgb+JGq\njv7ghjFH0BsfZMu+Ht5o7OaNpm5eb+pmS1MPjV37x9kpyw9xSnUBy2uLKQi7vtrKoyFOm1PE/NI8\nywUZM0ONuQ5KREqBlcD7gReBHwPnAR8ALpiIxJmZYTCZYk9HjF1tvexq7WNHSy9b9/WwdV8PDR39\nw+uFcnwsrMjnnAWlLKrMZ3FllJOrC6ksCGcw9caYTBlrHdTDwGLgh8DVqrrXW/RTEbHhMcywvoFB\nNjZ0DRfLbdrbxZZ93SMaKIQDPhaU57O8tpj3lM/h+FlRjq+MMrckYgO+GWOGjTUH9VVVfXK0Baq6\nfBzTY6aRtt4BNjd28XpjN5v3dvNyQydvNHWT9OqIyqMhlswu4Pzjy1hQls/c0gjzSiNURsNWLGeM\nOaKxBqgTReRFVe0AEJFi4K9U9ZsTlzQzVagq25p7eWZbC6/t7WLbvl62NffQ2jswvE5xJMDJ1YVc\nsmQBp80p4pSaQiqiVjRnjHnzxhqgPqqq3xj6oKrtIvJRXOs+M4OoKs3dcV5v6ub1xm5e3dPF09ta\naOpyw2wXRwIsrMjnkhMrWVCez+JZUU6YHaU8P2T9xBljxtVYA5RfRETVdd4vIn4gOHHJMpMhlVJ2\nt/Xx6h73UOtGr94oPWdUHg2xYn4J5y4o49yFpcwtiVggMsZMirEGqF/jGkR82/t8ozfPTCP9A0nW\n7Wrn6W0trN3VzqY9XXR7nZvm+ITjK6NctKSCJbMLWDwryuLKKKX5oSPs1RhjJsZYA9RncEHp77zP\njwP3TEiKzLjp6Btg3a521u1qZ+2udjbs7mAgmSLHJ5xcXci1y6o5qaqAk6oKOX5WPqEcf6aTbIwx\nw8b6oG4KuMubzBSUSimv7e1i7c42Xqrv5KW6Dra3uF64c3zCSVUFfOjcWs5ZUMqZtSXkhawbRmPM\n1DbW56AWAf8OnAgMN81S1eMmKF1mDPZ29vP8jjZ+/0Yzf3ijhZYe15ChIhpi6Zwirj+jhjPmFXNa\nTRG5QcsdGWOml7H+jP4e8AXgv4ELcf3y2ZgDkyiVUjY3dvPs9lbW7mpj/a6O4e6AiiIB3rqonAsW\nl3POglJmF+ZmOLXGGHPsxhqgclX1t15Lvl3AF0VkHfD5CUxbVnOD6HWydqerP3p+Rxud/a7Lw+qi\nXM6cX8Lpc4s4Y14xJ1UVWg8MxpgZZ6wBKi4iPmCLiPwD0ADkT1yysk8skWT97nae3dbKs9vb2FDn\nGjQA1JZGuOykWZx1XAlnHVdKdZHlkIwxM99YA9RNQAT4OPAvuGK+D0xUorLBUAu7F3a288LONl6p\n72QgmcIncEp1IR88t5Yz5hVzxrxiyqyptzEmCx0xQHkP5b5bVW8GenD1T+Yo9cQH+e2mJp7Z1sra\nXe1s3dcDQMAvnFJdyIfOreWs40o4s7aEaNjGMTLGmCMGKFVNish5k5GYmaY7luDJ15t59OU9PPl6\nMwODKQrCOZwxr5jrllUf3MJucAA6d0P9DuhuhIFeNyX6IRl3y5MDMBiHRJ+bP9gPyYQ3ecsT/TAY\nc+sNU0gl3XqpBKhCThgCYQhEIDobiudB0Tw3r2cf9DS51/526O9wr74cyC+HvAqIlICktQ4M5EJu\nEYSLILfYLY+UQrgQepuhfRd07IJ4N+SEICfXvfoDbj++HPB5r/6AW5br7SOvzKU/1ummZBxCBW7f\noaj7Xok+d75QCOZ7U2Tk9xa/S2cwz+1/eNmgty8ruTZmqhhrEd+LIvII8DOgd2imqv58QlI1jbX1\nDvCbVxv5zauNPL21lYFkiopoiJVnVnHt/EFOzuvB17cbetbC1r2wvgE6G6CzHroaAB1lr+KCiT+4\n/8YdyHVTTq6bH4yAr3D/spywe09a4wlfDvhzwBcAES/Q9bsbe2c91D0PG38OmnQ36/xKF4jKjt8f\neFKDLmj17nPpHU6uuuAQ63ABRFOjn6Bg1O1rKIAOxtw+D7X+ZAsXQkG1C4rpXTqFCvYH3WA+I84r\n6tKvKRfwUoNuSg64YBzvhngXBPIgWgn5s1yQDxe54wXz3To9TW4ajLv5uUXuuOD+Jqmkdxzdf8zh\nHyYJ9/eOlLh0hgq84B+CnCDIUKNb8bbzfugM9kNvq/t79jRBKuWOPXT8SKm3zxK3T5813jWTZ6wB\nKgy0Am9Pm6eABShcB6trd7Xz42d38dtXdlOb2s050SZurGllSc4eCvt2IRt2w4vJkRv6g+5mWFgD\n8893uZfiWjcVVO3PAeSER94sJ1LSu7kGjqEn8lTK3ZD726Cv3eW88krd98stHv27qHo39qTL6SQT\n7gba1wp9Le7Vl7P/5ukPupt6rMsdyx9wASAYAcTLfXbDQN/IwKwpL/fZB4lY2rIcl86uPe4HQ39b\nWtpS0Lsd+trc/OTAwekfMpwT9HKBoQKXwwtF3bloWAu9LYz+Q2R4J0dYnkGBvP25z+EfGXEXzAqq\nIFrl/j7JAZfLTSbSAquXWx3K4ScH3A+sYMTl4v0BL5CK2//Q/0Z0lvv7t26Fli3ub1c0111PhTXu\neon3uOthMOauJU0Buv9v4ctxy4Zz4An3IyE62/0QGwrqoag79vAPjkGv9KDNpUF1/4+1cMHI3Hko\n6vYXneX2daj/2VTK/bhr3QrtO/f/SEsNuvNbMt+7B1S7czRUkiI+l8MP5ru/QRb0iSle/68Ts3OR\ny4CvAH7gHlX90gHLPwX8DTAINAMf9pqxH9Ly5ct17dqpMUbiYDLFk88+x+t/+gWV3a9xmn8nC6UB\nH14g8odc7qN0gZtKFuz/h8srP/TN2kxd6hWV7p/hbhziG/vfMplwN7tYl7tZxrvcDS2/wk3+kJsX\n63DriHiBz+9eh44jPi9XHXRBNhHzimPbvZtwWpEw6uW8cNsP5az8IXctDh1b/N6xO91++rwbc1+r\nCwADPe5mORjfn1v3B9x63XtdgI93p6Ur4IKD+Lzi24D78ZMTdssSsf0/GJIJhnOGiX63r0Tf/vMW\nzHf/R8F86Njt5eDTct7ic99n6DzB/ht/KuGOGS50wcWf4xVj72NCfgz4g9739rtc59A1MvTjabD/\niLs4okDEK0mJuL/t0N97+AeBN+WEvR8BuWnnR7w0+dPS5l3bmnRBdCjXPlzC4V1DvhwXnEMF7nXF\nje4H9jEQkXWjjS04pgAlIt9jlL+iqn74MNv4gTeAS4B64AXcGFKvpa1zIfCcqvaJyN8BF6jquw+X\nlowHKFUSO55mxx/uI7zrd8zVPQDEgiUE5pyOv3oZzDoVKk50v4L81qWQMW+K6v5cbaTU/bBL/xEw\nOAA9je6mG4q6G/DR/uBLDrrizVjn/qLYwfj+G7fP7wJapMRNiPvh0N/h1k/Pnce7XN1x916XSx66\nsQ8FjKHgG4h4P1oXQclxJHwh6vd1EIsP7M+1DZUmiHjfyQsgqoBXzJv+fqjIefj7H1gErYz4kTJ0\nO08voh/abnjTA/eZJpXyjp1y5ycwtkdfwuEwNTU1BAIjG4IdKkCN9e75q/RjANcBe46wzQpgq6pu\n9xLwE+AdwHCAOmCU3meBlWNMz+Tr2E1yw0/of/4H5PfVMVcDbAyeSu/JH2HxudcRLj3OckPGjCeR\ntMAwipygK+o7Fv4cVzRZUDX2bcIFx37cNPU7dhAtLKK2tHRGD2WjqrS2tlJfX8/8+fPHtM1YO4t9\nKP2ziNwP/OkIm1UDdWmf64GzDrP+R4DHRlsgIquAVQBz547fhXFEsS7Y9Aj60v3Izj/hB15Onsiz\nhZ/kjEv/mreePH9GX1DGmIkXi8Wora2d8fcSEaG0tJTm5uYxb/Nmy58WARVvctuDiMhKYDnwttGW\nq+p3gO+AK+Ibr+Mekio892144osw2E9LoJofJN7FSyWX8b7LzueTJ1bO+IvJGDN5suV+crTfc6y9\nmXczsg6qETdG1OE0AHPSPtd48w7c98XA/wXepqrxA5dPusEBWP1pWP8Duua8nc80X8pvOmv4xMWL\n+d6FC63PO2OMmSRjeqhBVaOqWpA2HX9gsd8oXgAWich8EQkC7wEeSV9BRJYB3wauUdV9b+YLjKve\nVvjhtbD+B7xx/CqWb/8IL+kifnrjW/j4RYssOBljZpyOjg6++c1vHvV2V1xxBR0dHROQov3GFKBE\n5DoRKUz7XCQi1x5uG1UdBP4B+A2wCXhAVV8VkX8WkWu81b6M63T2ZyKywXsYODP6O+B7l0H9Wjac\n+WUue+UCTp9XyuqbzufM2kNU0hpjzDR3qAA1ODh42O1Wr15NUVHRRCULGHsd1BdU9eGhD6raISJf\nAH5xuI1UdTWw+oB5n097f/FRpHXipJLw0N9A23bWv+1ebvhNgGVzi/juB860kWeNMTParbfeyrZt\n21i6dCmBQIBwOExxcTGbN2/mjTfe4Nprr6Wuro5YLMZNN93EqlWrAKitrWXt2rX09PRw+eWXc955\n5/H0009TXV3NL3/5S3Jzj33UhbHefUfLac2cO/dvb4etj7Ntxb/wnseDLJkd5XsfsuBkjJlct//v\nq7y2p2tc93liVQFfuPqkQy7/0pe+xMaNG9mwYQNPPfUUV155JRs3bhxuCn7vvfdSUlJCf38/Z555\nJtdffz2lpaUj9rFlyxbuv/9+7r77bm644QYeeughVq489qeGxtqx1loRuUNEFnjTHcC6Yz76VPDy\nA/Dnr5BY9iH+ct0Saksj/ODDKyiwHsWNMVloxYoVI55T+upXv8ppp53G2WefTV1dHVu2bDlom/nz\n57N06VIAzjjjDHbu3DkuaRlrFuEfgduAn+Ja8z0O/P24pCCT2nbAI/8I887jO5Ebaevdzr0fPJPi\nvGCmU2aMyUKHy+lMlry8vOH3Tz31FE888QTPPPMMkUiECy64gFgsdtA2odD+Mev8fj/9/ePQlRNj\nf1C3F7h1XI44ldQ9B4Mxui/6Et+6dzcXL6lk6ZyJrfQzxpipJBqN0t3dPeqyzs5OiouLiUQibN68\nmWeffXZS0zbW56AeB/5SVTu8z8XAT1T10olM3IRr3Qri4zuvQndskE9dcnymU2SMMZOqtLSUc889\nl5NPPpnc3FwqKyuHl1122WV861vfYsmSJSxevJizzz57UtM21iK+sqHgBKCq7SIybj1JZEzrNpIF\nc/juMw1cdepsTqwqyHSKjDFm0t13332jzg+FQjz22Kg90A3XM5WVlbFx48bh+TfffPO4pWusjSRS\nIjLcCZ6I1DJlB6w5Cm3b2KGziSWSfOJiyz0ZY8xUMtYc1P8F/iQiv8f1wX4+Xuet05YqqdZtPB07\nj+uW1bCwwob6NsaYqWSsjSR+LSLLcUHpRdwDuuPTTCNTepvxDfSwLVnJP759YaZTY4wx5gBjbSTx\nN8BNuA5fNwBnA88wcgj4aUVbtiBAqGIRtWV5R1zfGGPM5BprHdRNwJnALlW9EFgGTGwvgRNs15ZX\nAFi69PQMp8QYY8xoxhqgYqoaAxCRkKpuBhZPXLIm3s43Xiahft624oxMJ8UYY8woxhqg6kWkCFf3\n9LiI/BLYNXHJmlixRJKBfVtpD1WRlxvOdHKMMSZj3uxwGwB33nknfX1945yi/cY6HtR1qtqhql/E\ndXn0XeCww21MZb95tZE5upec8kWZTooxxmTUVA5QR91dt6r+fiISMpkeWrubb/uaCNdclemkGGNM\nRqUPt3HJJZdQUVHBAw88QDwe57rrruP222+nt7eXG264gfr6epLJJLfddhtNTU3s2bOHCy+8kLKy\nMp588slxT1vWjSext7OfLdu2kBuKQ9mCTCfHGGP2e+xWaHxlfPc56xS4/EuHXJw+3MaaNWt48MEH\nef7551FVrrnmGv7whz/Q3NxMVVUVjz76KOD66CssLOSOO+7gySefpKysbHzT7BlrHdSM8fCLDdRK\no/tQYgHKGGOGrFmzhjVr1rBs2TJOP/10Nm/ezJYtWzjllFN4/PHH+cxnPsMf//hHCgsLj7yzcZB1\nOaj1uzq4oLwbOoFSC1DGmCnkMDmdyaCqfPazn+XGG288aNn69etZvXo1n/vc57jooov4/Oc/P8oe\nxlfW5aDu/usz+ODxSfCHoKAm08kxxpiMSh9u49JLL+Xee++lp6cHgIaGBvbt28eePXuIRCKsXLmS\nW265hfXr1x+07UTIuhyUiBDq2gkl88GXdfHZGGNGSB9u4/LLL+e9730v55xzDgD5+fn86Ec/YuvW\nrdxyyy34fD4CgQB33XUXAKtWreKyyy6jqqpqQhpJiOr06pR8+fLlunbt2mPbyTfOgtKF8J4fj0+i\njDHmTdq0aRNLlizJdDImzWjfV0TWqeryA9fNvixEKglt26HkuEynxBhjzGFkX4DqrIfkgDWQMMaY\nKS77AlTbNvdqTcyNMVPEdKtqebOO9ntmX4Bq9QKU5aCMMVNAOBymtbV1xgcpVaW1tZVweOz9n2Zd\nKz7atkMgAtHZmU6JMcZQU1NDfX09zc3NmU7KhAuHw9TUjP3xnuwLUK3bXAMJkUynxBhjCAQCzJ8/\nP9PJmJKyL0Bd/AWIdWY6FcYYY44g+wJU5UmZToExxpgxyL5GEsYYY6aFadeThIg0c+yj+ZYBLeOQ\nnJnEzslIdj4OZudkJDsfB0b/0pUAACAASURBVHuz52SeqpYfOHPaBajxICJrR+tWI5vZORnJzsfB\n7JyMZOfjYON9TqyIzxhjzJRkAcoYY8yUlK0B6juZTsAUZOdkJDsfB7NzMpKdj4ON6znJyjooY4wx\nU1+25qCMMcZMcRagjDHGTElZF6BE5DIReV1EtorIrZlOz2QTkTki8qSIvCYir4rITd78EhF5XES2\neK/FmU7rZBIRv4i8KCK/8j7PF5HnvOvkpyISzHQaJ5OIFInIgyKyWUQ2icg5do3IJ73/mY0icr+I\nhLPtOhGRe0Vkn4hsTJs36nUhzle9c/OyiJx+tMfLqgAlIn7gG8DlwInAX4nIiZlN1aQbBD6tqicC\nZwN/752DW4Hfquoi4Lfe52xyE7Ap7fN/AP+tqguBduAjGUlV5nwF+LWqngCchjs3WXuNiEg18HFg\nuaqeDPiB95B918n/AJcdMO9Q18XlwCJvWgXcdbQHy6oABawAtqrqdlUdAH4CvCPDaZpUqrpXVdd7\n77txN55q3Hn4vrfa94FrM5PCySciNcCVwD3eZwHeDjzorZJt56MQeCvwXQBVHVDVDrL4GvHkALki\nkgNEgL1k2XWiqn8A2g6Yfajr4h3AD9R5FigSkaMa5yjbAlQ1UJf2ud6bl5VEpBZYBjwHVKrqXm9R\nI1CZoWRlwp3A/wFS3udSoENVB73P2XadzAeage95xZ73iEgeWXyNqGoD8J/Ablxg6gTWkd3XyZBD\nXRfHfL/NtgBlPCKSDzwEfEJVu9KXqXv2ICuePxCRq4B9qrou02mZQnKA04G7VHUZ0MsBxXnZdI0A\nePUq78AF7yogj4OLurLeeF8X2RagGoA5aZ9rvHlZRUQCuOD0Y1X9uTe7aSj77b3uy1T6Jtm5wDUi\nshNX5Pt2XP1LkVeUA9l3ndQD9ar6nPf5QVzAytZrBOBiYIeqNqtqAvg57trJ5utkyKGui2O+32Zb\ngHoBWOS1vAniKjkfyXCaJpVXv/JdYJOq3pG26BHgA977DwC/nOy0ZYKqflZVa1S1Fnc9/E5V3wc8\nCbzLWy1rzgeAqjYCdSKy2Jt1EfAaWXqNeHYDZ4tIxPsfGjonWXudpDnUdfEI8Ndea76zgc60osAx\nybqeJETkClydgx+4V1X/LcNJmlQich7wR+AV9te5/BOuHuoBYC5uOJMbVPXAytAZTUQuAG5W1atE\n5DhcjqoEeBFYqarxTKZvMonIUlyjkSCwHfgQ7gdt1l4jInI78G5cS9gXgb/B1alkzXUiIvcDF+CG\n1WgCvgD8glGuCy+Qfx1XFNoHfEhV1x7V8bItQBljjJkesq2IzxhjzDRhAcoYY8yUZAHKGGPMlGQB\nyhhjzJRkAcoYY8yUZAHKmGlKRC4Y6n3dmJnIApQxxpgpyQKUMRNMRFaKyPMiskFEvu2NPdUjIv/t\njS/0WxEp99ZdKiLPeuPnPJw2ts5CEXlCRF4SkfUissDbfX7auE0/9h6ONGZGsABlzAQSkSW43gfO\nVdWlQBJ4H66z0bWqehLwe9wT+QA/AD6jqqfievsYmv9j4BuqehrwFlyP2uB6o/8Ebnyz43D9wxkz\nI+QceRVjzDG4CDgDeMHL3OTiOtNMAT/11vkR8HNvHKYiVf29N//7wM9EJApUq+rDAKoaA/D297yq\n1nufNwC1wJ8m/msZM/EsQBkzsQT4vqp+dsRMkdsOWO/N9jmW3u9bEvufNjOIFfEZM7F+C7xLRCoA\nRKRERObh/veGesF+L/AnVe0E2kXkfG/++4HfeyMf14vItd4+QiISmdRvYUwG2K8tYyaQqr4mIp8D\n1oiID0gAf48bBHCFt2wfrp4K3HAF3/IC0FAv4uCC1bdF5J+9ffzlJH4NYzLCejM3JgNEpEdV8zOd\nDmOmMiviM8YYMyVZDsoYY8yUZDkoY4wxU5IFKGOMMVOSBShjjDFTkgUoY4wxU5IFKGOMMVOSBShj\njDFTkgUoY4wxU5IFKGOMMVOSBShjjDFTkgUoY4wxU5IFKGMyRET+R0T+dYzr7hSRi491P8ZMJxag\njDHGTEkWoIwxxkxJFqCMOQyvaO0WEXlZRHpF5LsiUikij4lIt4g8ISLFaetfIyKvikiHiDwlIkvS\nli0TkfXedj8Fwgcc6yoR2eBt+7SInPom0/xREdkqIm0i8oiIVHnzRUT+W0T2iUiXiLwiIid7y64Q\nkde8tDWIyM1v6oQZM44sQBlzZNcDlwDHA1cDjwH/BJTj/oc+DiAixwP3A5/wlq0G/ldEgiISBH4B\n/BAoAX7m7Rdv22XAvcCNQCnwbeAREQkdTUJF5O3AvwM3ALOBXcBPvMV/AbzV+x6F3jqt3rLvAjeq\nahQ4Gfjd0RzXmIlgAcqYI/uaqjapagPwR+A5VX1RVWPAw8Ayb713A4+q6uOqmgD+E8gF3gKcDQSA\nO1U1oaoPAi+kHWMV8G1VfU5Vk6r6fSDubXc03gfcq6rrVTUOfBY4R0RqcUPFR4ETcGPBbVLVvd52\nCeBEESlQ1XZVXX+UxzVm3FmAMubImtLe94/yeWjo9ipcjgUAVU0BdUC1t6xBR44Quivt/Tzg017x\nXoeIdABzvO2OxoFp6MHlkqpV9XfA14FvAPtE5DsiUuCtej1wBbBLRH4vIucc5XGNGXcWoIwZP3tw\ngQZwdT64INMA7AWqvXlD5qa9rwP+TVWL0qaIqt5/jGnIwxUZNgCo6ldV9QzgRFxR3y3e/BdU9R1A\nBa4o8oGjPK4x484ClDHj5wHgShG5SEQCwKdxxXRPA88Ag8DHRSQgIu8EVqRtezfwtyJylteYIU9E\nrhSR6FGm4X7gQyKy1Ku/+n+4IsmdInKmt/8A0AvEgJRXR/Y+ESn0iia7gNQxnAdjxoUFKGPGiaq+\nDqwEvga04BpUXK2qA6o6ALwT+CDQhquv+nnatmuBj+KK4NqBrd66R5uGJ4DbgIdwubYFwHu8xQW4\nQNiOKwZsBb7sLXs/sFNEuoC/xdVlGZNRMrJI3BhjjJkaLAdljDFmSrIAZYwxZkqyAGWMMWZKsgBl\njDFmSsrJdAKOVllZmdbW1mY6GcYYY8bJunXrWlS1/MD50y5A1dbWsnbt2kwnwxhjzDgRkV2jzbci\nPmOMMUdPFfraYKB3wg4x7XJQxhhjxsFgHGJdEPemVBLEBz4/pAahZx90N0JPE/S371+3rxW697pl\ngzF4591w6g0TkkQLUMYYM92pQtceaHwFOnZDos8Fj4Fel8vpa4HeFhdo4l0u2CTjY99/qADChe41\ntxiql0PBbIhWweylE/a1LEAZY0ymDA6QSCr1e/YQi8X2z0+lQJPeB6+3n1QSkglIJdz7ofmKy/Fo\nEhBgHvhxU1ig0O9yRgdNMvLzgcQPPp97HdHH8QFaktCyaUxfNxwOU1NTQyAQGNP6FqCMMWY8JQdd\nTmUwBskB99rb7HI4XQ0uh9O6Hdq2Qfde6s/+EtEFZ1JbFEJEXLBhtC7oBAiCLw9yDhjHMicEObkQ\nyHXv04PQFKGqtLa2Ul9fz/z588e0jQUoY4wZTbwbuva6OpieJhdk+jtgsB8Ssf2viT439bV6dTb7\nGD3AeCJlULoAjrsQiucRK1xKbXklol4H8v4A+HLcJIILTN78nLCrI5qGRITS0lKam5vHvI0FKGPM\nzNff4YJHrMO9j3d7OZy4ayzQ2+yCUbc3de2Fge7R9+UPQSC8P8cSiLjP+ZUw+zSIznZBKBB26+YE\nIa8cCqrcskDuyP1t2oQUzZn4czAFyFHm6LIvQO3b7LLf82zAUGNmhFQS9r4E2590QcgfdDkNTbr/\n96aN0Fl3+H34Ai54RGdB+Qmw4O3uc0GVCzz5lZBfAeEiVy9jJkX2Bag1n3NlwR97OtMpMcYcykAv\nNG92AablDRdw8itcoPDluIDTWe/qcXb+yf3oBNfSLJlwuSKAskUw5yw48yNQOAdyiyBcDKGolwsK\nu4AWKsjawNPR0cF9993Hxz72saPa7oorruC+++6jqKhoglKWjQFq9qmw7Xeu7DgQznRqjJn5Uilo\n3Qr1L0DvPpdb8eWApqB7jws0nQ1eE+huGOhx0xBfYPSGA/4gFNbA4itcfc5xF0B+Wm85qlOqkcBU\n1dHRwTe/+c2DAtTg4CA5OYcOEatXr57opGVhgJp1qpf1fw2qT890aoyZXhIxiHW6uptQgZtEoG27\ny8ns/CO073IByB9wQajxFVf3Mxp/CAqroaAaZp3scjbBKESKoWwxVJwIxbWAuud4ehpdkV5hDeRV\nHD7XY8FpTG699Va2bdvG0qVLCQQChMNhiouL2bx5M2+88QbXXnstdXV1xGIxbrrpJlatWgXs73au\np6eHyy+/nPPOO4+nn36a6upqfvnLX5Kbm3uEIx9Z9gWo2ae618aXLUAZM6S/A/ZtcjmcwQEXgOLd\n0LoNWre41559ozzcKRDM25/jya90dTiacsVsmoIT3wE1Z8KcFa6YLTXo5YhwD32ONZAUzHbTDHb7\n/77Ka3u6xnWfJ1YV8IWrTzrk8i996Uts3LiRDRs28NRTT3HllVeycePG4abg9957LyUlJfT393Pm\nmWdy/fXXU1paOmIfW7Zs4f777+fuu+/mhhtu4KGHHmLlypXHnPbsC1BFte5X396XM50SYyaPqgsw\nbduhY5crVutqgI46F5i66kffLhiFsoUw9xwXHMKFbvKHXE4q1uF6JShbBPPf5l4t5zKtrVixYsRz\nSl/96ld5+OGHAairq2PLli0HBaj58+ezdKnrUeKMM85g586d45KW7AtQPh/MOsXloIyZrhL9rvFA\nf8f+rmtina4eZ2hKn9+xGxIHdOqZW+KK1+adA5UnQcVJ7rM/5IrnAhHIK7OAM4kOl9OZLHl5ecPv\nn3rqKZ544gmeeeYZIpEIF1xwwcgeLzyh0P4Hh/1+P/39/eOSlqwLUK/u6aQgtJA5O37myrKn6UNv\nZoZKpVy/abHOkTmUoWDTugUaXnR1qMNd4aQRn2sKPZTTCRd4D4VeACXHual4nqvzCUYm+9uZKSga\njdLdPfozX52dnRQXFxOJRNi8eTPPPvvspKYt6wLUf/z6dRY2FPD5ZJ8rVy8/PtNJMtlgoM91e+MP\nuimVcMVrHbuhYyc0veYaEzS9enBOJ124yNWdHv8J1+AnUuqCUKjANaEOFWZtc2nz5pSWlnLuuedy\n8sknk5ubS2Vl5fCyyy67jG9961ssWbKExYsXc/bZZ09q2rIuQL3vrLnc+aMqCOGK+SxAmfGUSkHL\n67Drz9Cw3tX5tO1wrc8OJ1Tgip5Pfz+ULkzLBXnBZ+g1FLUiNzPu7rvvvlHnh0IhHnvssVGXDdUz\nlZWVsXHjxuH5N99887ilK+sC1EUnVHB7/nEkEgECe1+CU96V6SSZ6ULVPQTasds901P/vMv1pAa9\n3qC95tb9bW79vHIoOx4WXeyaSgfyXC4qmXBBpnAOFM2FojmuyM0CjzEjZDxAiUgRcA9wMu5JvA+r\n6jMTdbwcv493nTmfzX+qZlHdBuxR3Syn3vM1bdtd7wRD/bB173X9s/W2uNdEn2uYkP6waDAKVUtd\n32qactPiK2DeW1zDg+L5FnSMOQYZD1DAV4Bfq+q7RCQITHjN7btXzOVPf6xlwd4X7WnzbBDvhuY3\nXNc5Hbv3907dtccFpvgBz50E8lyfbPkVXhPrsyGU77rFGepyp+ZMlzuyRjbGTJiMBigRKQTeCnwQ\nQFUHgIGJPm51US6J8lOItD1For2OQMnciT6kmQgDva7Xgo7drrXbQA/Ee9ywB10Nrvuczjr3Pl2k\nzAWg6Cz38GjJcVCywBW1Rb1nfexHizEZl+kc1HygGfieiJwGrANuUtXDNGMaHyecfi488TVeeuGP\nLL/0fRN9OPNmDT1g2rHb5YCaXnW9Uze/7no9GI0/5HqhLqyB+W91D4+Wn+CmornuGR9jzJSX6QCV\nA5wO/KOqPiciXwFuBW5LX0lEVgGrAObOHZ/czrLl55F6Qtj16jMWoDIp1umK2rr3uqESOhugc7dr\ngt1Z517Tu9cJ5EHliXD8pVAyH4rmuQYIucUQzHdFcYGI5YCMmQEyHaDqgXpVfc77/CAuQI2gqt8B\nvgOwfPnywwxVOXb+cJT23LlE219jS1M3iyqj47Fbcyh9ba7ng+bX3bTvNdfFzmjNr/MqXHFb5cmw\n+HIXhArnuJxQ8Xx7zseYcfRmh9sAuPPOO1m1ahWRyMQ0HchogFLVRhGpE5HFqvo6cBHw2mQdPzLv\ndE7e/Ec+9cuN3P/Rs496tEfjScTccAqddftzQ8Ojkza6IRWGxusBNxJp+WI3KFz5YlcUNzRYXEHV\nwSOOGmMmzKGG2xiLO++8k5UrV87MAOX5R+DHXgu+7cCHJuvAoZqlVG1+mM3bd/Hz9XO4/oyayTr0\n9NOzD/ZscB2N9rW57ni697oB5dq2j+x2R3yuV+vobFf8Nvds1xCh7Hj3YHThHGv9ZswUkT7cxiWX\nXEJFRQUPPPAA8Xic6667jttvv53e3l5uuOEG6uvrSSaT3HbbbTQ1NbFnzx4uvPBCysrKePLJJ8c9\nbRkPUKq6AViekYPPWQHAnUU/5ZZHi3j7CRUU5wUzkpQpIdHvej1o3+l1wbPbBZ+9L7lcULpQoWtu\nXb4YTrrWNUAonu96vM6rAH/GLy1jpp/HbnUPf4+nWafA5V865OL04TbWrFnDgw8+yPPPP4+qcs01\n1/CHP/yB5uZmqqqqePTRRwHXR19hYSF33HEHTz75JGVlZeObZk9230XmngMXfo4LnvxX/iXVw//3\naBn/fkNmYuWkSqWgfYcLPHtfcl0+tXhFdOkPoubkuo5Fa8+FqmUwe6nreDS3BHKyOJAbM0OtWbOG\nNWvWsGzZMgB6enrYsmUL559/Pp/+9Kf5zGc+w1VXXcX5558/KenJ7gAlAm+7BYJ5XPabzxJ65VM8\nv/R+VhxfnemUHbuBXm/sn7QWcW07oG2bex1qGecLQMUJMPcsKH2f6weueL4LTJFSaw1nzGQ6TE5n\nMqgqn/3sZ7nxxhsPWrZ+/XpWr17N5z73OS666CI+//nPT3h6sjtADTnnY8T9ubxt9SfZfv9ltLzz\nDspOuSTTqTo8VdcwYfez7sHUWMf+cX+a33BNtdPlhF3gKVkAiy6B0kUw+zSoWAI5odGPYYyZ8dKH\n27j00ku57bbbeN/73kd+fj4NDQ0EAgEGBwcpKSlh5cqVFBUVcc8994zY1or4JlhoxYeo0yLCq2+h\n7KF3MbDxHQQv/1f3YGcmqbqueDobvN4R6mHPi7DtyZFByJfjekAoqHJ1a6e/3zXLLpoLhXNt4Dlj\nzKjSh9u4/PLLee9738s555wDQH5+Pj/60Y/YunUrt9xyCz6fj0AgwF133QXAqlWruOyyy6iqqpqQ\nRhKiOi6PFU2a5cuX69q1ayds/8++Xs+zP/oif+d/hKAvicx/Kyy5GhZfCdHKI27/piQTrgiuZat7\nVqjlDVdH1LXHNdc+cHygUIHrIWHB290w2wWz7eFUY6apTZs2sWTJkkwnY9KM9n1FZJ2qHtQAYFxz\nUCJyE/A9oBvXQ/ky4FZVXTOex5lIZy+uoen627nwJ+fzxdnPcEn788ivPgm/+pRrJj3rFDeVnwD5\n5W5IhUiZe3bnwACh6joq7d7rcj9de1wnpb2tXjPtRtdirrN+ZDPtSKlrll15Eiz6C9dce6jrnoJq\n99layRljZrjxvst9WFW/IiKXAsXA+4EfAtMmQAG8Y2k1+7rOZ9XqMt626EPc9c48ItsfcwPQ1T0H\nGx88eCNfDgTz3BAMIq5YLt7thmA4UDDfBaH8Clccd8pfukYJpYtcEMwrnfgvaYwxU9x4B6ihLMQV\nwA9V9VWZpt0zfPStx5EfzuFzv9jI9Q8NcO8H/4HZb/V6OOhrc8PF97XsHy8o3u1azg30uKCUPgpq\nQZWbhnpLsJ4SjDFpVDUrerI52iql8Q5Q60RkDa6X8s+KSBQYJQsxPfzVirlUFeXy9z9ez7Xf+DN3\n//VyTq0pgkiJm4wx5hiFw2FaW1spLS2d0UFKVWltbSUcHvswsePaSEJEfMBSYLuqdohICVCjqi+P\n1zEmupHEaDbt7eIj//MC+7rjfOovjufGty7A75u5F5IxZvIkEgnq6+uJxWKZTsqEC4fD1NTUEAiM\nHPLmUI0kxjtAnQtsUNVeEVmJG0rjK6q6a7yOkYkABdDRN8A/PfwKq19p5Kz5Jdzx7qVUF1lRnTHG\nHKtDBajxHrfgLqDPG3zw08A24AfjfIyMKIoE+cZ7T+fL7zqVjQ2dXPrff+B7f97BYHLalmAaY8yU\nNt4BalBdluwdwNdV9RvAjBloSUT4y+VzWH3T+SybW8Tt//sa13z9z6zf3X7kjY0xxhyV8Q5Q3SLy\nWVzz8ke9OqkZN772vNI8fvDhFXzzfafT1jvAO7/5NDf95EV2tU74SPXGGJM1xjtAvRuI456HagRq\ngC+P8zGmBBHhilNm88Sn38bHLljAb15t5KL/+j2f+8UrNHXN/MpOY4yZaOPe1ZGIVAJneh+fV9V9\n47n/TDWSOJJ9XTG+9rut3P/8bnw+4YblNdz41gXMKZmYkSaNMWammKxWfDfgckxP4R7aPR+4RVVH\n6XrhzZmqAWrI7tY+7vr9Nh5aV09SlWtOq+Ij583n5OrCTCfNGGOmpMkKUC8BlwzlmkSkHHhCVU8b\nr2NM9QA1pLEzxj1/3M59z++mbyDJGfOK+cBbarnspFkEc8a7ZNUYY6avyQpQr6jqKWmffcBL6fOO\n1XQJUEM6+xM8uK6eHzyzk12tfZTlB7luWTU3LJ/DosoZ08DRGGPetMkKUF8GTgXu92a9G3hZVT8z\nXseYbgFqSCql/H5LMz95fje/3bSPwZSybG4R159ew9WnVlEYmXGNHY0xZkwmJUB5B7oeONf7+EdV\nfXg89z9dA1S6lp44D69v4Gfr6nijqYdgjo9LllRyzdIq3nZ8OeGAP9NJNMaYSTNpAWqizYQANURV\n2djQxUPr6/nlhgba+xJEgn7efkIFl588m7ctLic/ZOM+GWNmtgkNUCLSDYy2IwFUVQuO+SCemRSg\n0iWSKZ7d3srqVxpZ82ojrb0DBP0+zl1YyiUnzuLiJRVUFIy9F2BjjJkuLAc1jQwmU6zd1c7jrzWx\n5rVG6tr6ATi1ppCLTqjkgsXlnFRVQI7fWgMaY6a/KR2gRMQPrAUaVPWqw62bDQEqnaqyubGb323e\nxxObmthQ14EqREM5LK8t5uzjSjl3YRknzi7AZ0OAGGOmoUMFqKlSwXETsAkYt6LAmUJEWDK7gCWz\nC/j7CxfS0hPn6W2tPLvdTU++3gxAcSTAWxaWcfb8EpbNLeaEWVHLYRljprWMBygRqQGuBP4N+FSG\nkzPlleWHuOa0Kq45rQqApq4YT29r4U9bWvnz1hYefXkvAJGgn9NqijhjXjFnzCtm2dwiiiLBTCbd\nGGOOSsaL+ETkQeDfccNy3DxaEZ+IrAJWAcydO/eMXbvGbfzDGUVVqW/vZ/3udtbvamfd7nY27e0m\nmXJ/4+PK8ji1ppBTaoo4raaQJbMLyLNWgsaYDJuSdVAichVwhap+TEQu4BABKl221UEdq76BQTbU\ndbB+Vzsv1XfySn0njV5v6yIwvyyPk6sKObGqwCtKjFIRtdaCxpjJM1XroM4FrhGRK4AwUCAiP1LV\nlRlO14wRCebwlgVlvGVB2fC8pq4Yr9R38uqeLjbu6WTtzjYeeWnP8PKy/CBLZhdwwqwoi2e514UV\n+fYAsTFmUmW8iG+I5aAyq6NvgNf2drFpbzeb93axqbGLN5p6GBh0Q9r7BGrL8lhcGWVRZZRFFfks\nrMhnflmeBS5jzDGZqjkoM0UURYIH5bQGkyl2tvayubGb1xu72exNv3m1kVTa75qqwjDzy/OYV5rH\n3JIIc0sizCuNsKDccl3GmDdvyuSgxspyUJkXSyTZ0dLL1n097GjpZWdLL9taeqlr66Otd2B4PRGY\nWxJhUUU+c0oiVBflUlOcS01xhPlledZAwxgDWA7KjKNwwD/8bNaBumMJ6tr62dHSy5Z93Wxp6mHL\nvm6e3tZK30ByxLrl0RDzS/OoLs6lqijM7MK018JcCnJzELGHj43JVhagzLiKhgOcWBXgxKoCYPbw\nfFWlsz9BfXs/dW197GjtZUdzLztbe3l+RxuNXbHh5vBD8oJ+qotzmVMcoaY4l9lFucwqCDOrMDz8\nakWIxsxcFqDMpBARiiJBiiJBTq4uPGh5MqU0d8fZ09nP3o4Yezv7aejop6G9n/r2fp7f2UZ3bPCg\n7QpzA8wqCFNREKI8GqIiGqYiGqKqKMyswlyqCsOU5ofwWzdQxkw7FqDMlOD3icsZFYZh7ujr9MQH\naeyM0dQVY6/32tgZo7Erxr7uONube2nujjOQTB207/L8EJUFISoKwl4gcwGtxAuaJXlBSvODFEeC\nFsyMmSIsQJlpIz+Uw0KvefuhqCptvQPs7XRBrLGzn6auuAtmXTHq2vpYt6t9RGOOdD6B0vwQ5fmh\n4YA5qyBMWX6IkrwAJXkhF8zyghTmBqyDXmMmkAUoM6OICKX5IUrzQ6MWJQ5JJFO09gzQ1jtAR98A\nbX0DtPYM0NITp7k7zr7uOI2dMV6q66D1EMHM7xOKI0GKIwGKIgEKc13gKo+GqCgIUZYfojA3QGFu\ngIKwe42GcyyoGTNGFqBMVgr4ffuLFI8gPpikrXdgeGrtGaC1d4C23rgX4BJ09CWob+/j5foOWnri\npA7x9IYIFIRdQCvKDXj1cgFK80KURYOU5YUoigSIBHOIhPzkBXMozgtQEgla7/Qm61iAMuYIQjl+\nZhfmMrswd0zrJ1OumLGlJ05Xf4JOb+qKDdLZN0Bnf4L2vgQd/Qna+wbY3tJDa8/AQc3wD1QcCVAc\nCRLNDVAQzqEgLWdWmPv/t3dvMZJUdRzHv7+u6u6Z6dllWViJLiAgREUjFwmuooaAD6BEeMArKCEa\nX0gEo1EwGqOJDyZGckz+OwAACYhJREFU1EgQA+gSCaIISnww6kpQHriDiqCRIJdFlt2FvcxMT3dX\nVf99OKdne2fYhd2d6e6d+n+SznRV13SfOTkzvzmXqqqycjxlxVh4bcVYSqOe0qilTNQSVvncmjsI\neUA5t8iSilgTF2Hsi2Yn56Xp0CNrdnKaWcFMO2fbTIet0x1emmmzvRmDLi7Zn2qF8MuKvZ9wXxGs\nbtQ5fDIsBpmsp0zWq0zWE8aqCfW0Qi2tsHK8yprJXUOUk/UQdPW04uekuYHzgHJuREzUUiZWpxy1\net++z8yYzQqmWnkMrPB1tlMw3c6Zaee8PNNhy3SHLVNttjU7vDTdZKqVM93OaecF7bzL3i4qUxGM\nV0OYjVUTxmsJq+Pqx0MbNcarCbUYcmPVylzPrVFPWTkWeneHjIehy/Fawlha8SFL96o8oJw7yEkK\n4VZLOWLl/t0qxczIinAy9eapFlum2myd7tDs5My0C5qdnNlOwWxW0Mq6oWcXhydffiajlRV08u6C\nJf57U0tCj623yKRRTxmvJiEIawmNWsJ4L+j6nveCr1FLadTD80nv5S1LHlDOOSRRS/dvaLJft2u0\n824YouwUzHRyplo5O5phKLLZyWllXWaz8NrO2bDAZFszLECZ7RS08oLZTkEzPl6ratIL6tDD6wXY\nZD2sngy9v0r4mu56Pl5NqPc9b9ST2OsL31dPE5+/GxIPKOfcoqlUxHgMiMMW4f26XaOVx7BqFzSz\nMGTZ69VNt8M83XQ7BGGvp9fMCprxuP9tn2WqnTHb6dLOQgC+2pzdfBJUKxWqifqGMhNWjKVzi1TG\nqkk4JhW1JGHleDoXdOMxHOtpGApNKqKaiLRSmQvH3jxgLamQVkRSUel7hB5QzrmRVansGr5kz+dn\n77Oia7SyIjzyLq0s9NpaWcFMp2DnbMbOVsbO2ZxO3iXvdsm7FoYx46OVF3OrNDftaNHKumRFOK4d\n3+dAVASNesqKelidORlXZ64Yq9KoJUhCAgETtV09xUY9hGA16T1ERSEMewFbT0OvcTIOj07E9xs1\nHlDOudJJKgrzWEt4y5e86DLdztk5m9PKQ/i18y7tLAZeYeTdLu0YkL3XsvhaJw/fH3qHGVOtsMrz\n6a0zzHSKuKjF6Bpz84P7a/4imFpaQQAxAPsXu4xVEzAoLHz2Re86mnXHLUZ/eSEPKOecWwJpUpm7\nQPIgZEVYvDLTKcjigpVO3qXoGnnXKLpGFve187jYpZMzHVdzNmMPspWF7zUzjLCAphl7lZt2tpjt\nFFQqUJFIJLY3syX7mTygnHNuGajOBeKwS7J4/EQE55xzI8kDyjnn3EiS7e308REkaQvwzAG+zeHA\n1kUoznLidbI7r4+FvE525/Wx0P7WyRvNbM38nQddQC0GSQ+a2WnDLsco8TrZndfHQl4nu/P6WGix\n68SH+Jxzzo0kDyjnnHMjqawB9ZNhF2AEeZ3szutjIa+T3Xl9LLSodVLKOSjnnHOjr6w9KOeccyPO\nA8o559xIKl1ASTpH0r8lPSnpymGXZ9AkHSXpLkmPS/qnpMvj/tWS/ijpP/HrocMu6yBJSiQ9Iul3\ncftYSffFdnKrpMFcUG1ESFol6TZJ/5L0hKR3exvRF+LvzGOSbpE0VrZ2IulGSZslPda37xXbhYIf\nxrr5u6RT9/XzShVQkhLgGuBc4ETgE5JOHG6pBi4HvmhmJwLrgMtiHVwJbDCzE4ANcbtMLgee6Nv+\nDnC1mR0PbAM+M5RSDc8PgN+b2VuAkwh1U9o2Imkt8HngNDN7O5AAH6d87eRnwDnz9u2pXZwLnBAf\nnwOu3dcPK1VAAacDT5rZU2bWAX4BnD/kMg2Umb1gZg/H51OEPzxrCfWwPh62HrhgOCUcPElHAh8C\nro/bAs4CbouHlK0+DgHeD9wAYGYdM9tOidtIlALjklJgAniBkrUTM/sL8PK83XtqF+cDN1lwL7BK\n0uv35fPKFlBrgef6tjfGfaUk6RjgFOA+4AgzeyG+tAk4YkjFGobvA18GunH7MGC7meVxu2zt5Fhg\nC/DTOOx5vaQGJW4jZvY88F3gWUIw7QAeotztpGdP7eKA/96WLaBcJGkS+DVwhZnt7H/NwrkHpTj/\nQNJ5wGYze2jYZRkhKXAqcK2ZnQLMMG84r0xtBCDOq5xPCO83AA0WDnWV3mK3i7IF1PPAUX3bR8Z9\npSKpSginm83s9rj7xV73O37dPKzyDdgZwIclPU0Y8j2LMP+yKg7lQPnayUZgo5ndF7dvIwRWWdsI\nwAeA/5rZFjPLgNsJbafM7aRnT+3igP/eli2gHgBOiCtvaoRJzjuHXKaBivMrNwBPmNn3+l66E7gk\nPr8E+O2gyzYMZnaVmR1pZscQ2sOfzewi4C7gwnhYaeoDwMw2Ac9JenPcdTbwOCVtI9GzwDpJE/F3\nqFcnpW0nffbULu4EPh1X860DdvQNBb4mpbuShKQPEuYcEuBGM/v2kIs0UJLeC/wV+Ae75ly+SpiH\n+iVwNOF2Jh81s/mTocuapDOBL5nZeZKOI/SoVgOPABebWXuY5RskSScTFo3UgKeASwn/0Ja2jUj6\nJvAxwkrYR4DPEuZUStNOJN0CnEm4rcaLwDeA3/AK7SIG+Y8IQ6FN4FIze3CfPq9sAeWcc+7gULYh\nPueccwcJDyjnnHMjyQPKOefcSPKAcs45N5I8oJxzzo0kDyjnDlKSzuxdfd255cgDyjnn3EjygHJu\niUm6WNL9kh6VdF2899S0pKvj/YU2SFoTjz1Z0r3x/jl39N1b53hJf5L0N0kPS3pTfPvJvvs23RxP\njnRuWfCAcm4JSXor4eoDZ5jZyUABXES42OiDZvY24G7CGfkANwFfMbN3EK720dt/M3CNmZ0EvIdw\nRW0IV6O/gnB/s+MI14dzbllIX/0Q59wBOBt4J/BA7NyMEy6m2QVujcf8HLg93odplZndHfevB34l\naQWw1szuADCzFkB8v/vNbGPcfhQ4Brhn6X8s55aeB5RzS0vAejO7ared0tfnHbe/1xzrv+5bgf9O\nu2XEh/icW1obgAslvQ5A0mpJbyT87vWugv1J4B4z2wFsk/S+uP9TwN3xzscbJV0Q36MuaWKgP4Vz\nQ+D/bTm3hMzscUlfA/4gqQJkwGWEmwCeHl/bTJingnC7gh/HAOpdRRxCWF0n6VvxPT4ywB/DuaHw\nq5k7NwSSps1sctjlcG6U+RCfc865keQ9KOeccyPJe1DOOedGkgeUc865keQB5ZxzbiR5QDnnnBtJ\nHlDOOedG0v8BRRO3fw4o3x8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlUpOBGJIFJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}