{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HTbJqGFwbrjR"
   },
   "source": [
    "# Mounting google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "qjwnv_eEbhpz",
    "outputId": "124141c4-3d5f-44c2-ade5-8c8e115d7e3e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CtzEwxVRcxUk"
   },
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TiUyYUWdcw9u",
    "outputId": "6b18250f-f289-482c-cdbb-e0143febf3c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0-dev20191121\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvLK5QhU0L34"
   },
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTCMZpr7cAga"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yu-mN1cF7XTB"
   },
   "outputs": [],
   "source": [
    "# open the file as read only\n",
    "with open('/content/drive/My Drive/Colab Notebooks/text-generation/text-generation-word/nips_clean.txt', 'r') as file:\n",
    "  corpus = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Ah-YYMW77kWJ",
    "outputId": "4ce3eb25-04cb-4c7f-a175-241226f49377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 784009\n",
      "Total number of unique words:  15032\n"
     ]
    }
   ],
   "source": [
    "words = corpus.split()\n",
    "n_words = len(words)\n",
    "unique_words = sorted(list(set(words)))\n",
    "n_unique_words = len(unique_words)\n",
    "print(\"Total number of words:\", n_words)\n",
    "print(\"Total number of unique words: \", n_unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7sNXXnDEIGSV"
   },
   "source": [
    "## Parameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQVt7zdjjH_C"
   },
   "outputs": [],
   "source": [
    "# Parameters configuration\n",
    "SEQUENCE_LENGTH = 200\n",
    "MIN_WORD_FREQUENCY = 3 \n",
    "MAX_VOCAB_SIZE = n_unique_words\n",
    "EMBEDDING_DIM = 256\n",
    "BATCH_SIZE = 32\n",
    "DROPOUT_RATE = 0.2\n",
    "RNN_UNITS = 128\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "pgt5_4HX-YXR",
    "outputId": "7f71969c-a2b5-40be-d748-d575eb83df04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing words with frequency < 3\n",
      "Total number of rare words:  7066\n",
      "Total number of unique words after removing rare words: 7966\n"
     ]
    }
   ],
   "source": [
    "# Calculate word frequency\n",
    "word_count = {}\n",
    "for word in words:\n",
    "  word_count[word] = word_count.get(word, 0) + 1\n",
    "\n",
    "rare_words = set()\n",
    "for k, v in word_count.items():\n",
    "  if word_count[k] < MIN_WORD_FREQUENCY:\n",
    "    rare_words.add(k)\n",
    "\n",
    "print('Removing words with frequency <', MIN_WORD_FREQUENCY)\n",
    "print('Total number of rare words: ', len(rare_words))\n",
    "unique_words = sorted(set(words) - rare_words)\n",
    "n_unique_words = len(unique_words)\n",
    "print('Total number of unique words after removing rare words:', n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRAL69H7HTj5"
   },
   "outputs": [],
   "source": [
    "# Parameters configuration\n",
    "MAX_VOCAB_SIZE = n_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QyfcHrPpINcK"
   },
   "source": [
    "## Create sequences of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lII3wDDPjv9T",
    "outputId": "f5e7f9a2-c2d1-4937-986f-57a6cc51ba92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sequences without rare words: 143211\n",
      "Total number of sequences with rare words: 640598\n"
     ]
    }
   ],
   "source": [
    "# Create sequences of words and remove sequences containing rare words\n",
    "sequences_words = []\n",
    "n_ignored = 0\n",
    "ignored_sequences = []\n",
    "for i in range(0, n_words - SEQUENCE_LENGTH):\n",
    "\ts = ' '.join(words[i:i+SEQUENCE_LENGTH])\t\n",
    "\t# only add sequences containing no rare words\n",
    "\tif len(set(words[i:i+SEQUENCE_LENGTH]).intersection(rare_words)) == 0:\n",
    "\t\tsequences_words.append(s)\n",
    "\telse:\n",
    "\t\tn_ignored = n_ignored + 1\n",
    "\t\tignored_sequences.append(s)\n",
    "\t\n",
    "print('Total number of sequences without rare words: %d' % len(sequences_words))\n",
    "print('Total number of sequences with rare words: %d' % len(ignored_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eb3-uI_ZIRbR"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "mfKBMQAY1a66",
    "outputId": "a90b3d1b-b972-474a-8f58-ee5f39a2325e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 7204\n",
      "Total number of sequences: 143211\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(filters='', lower=False, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sequences_words)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# convert the sequences into integers\n",
    "sequences = tokenizer.texts_to_sequences(sequences_words)\n",
    "n_sequences = len(sequences)\n",
    "# vocabulary size\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "print(\"Number of unique tokens: %d\" % len(word_index))\n",
    "print('Total number of sequences: %d' % n_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KF-Gtu3TIVk-"
   },
   "source": [
    "## Create input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1pTRtLAmNDS"
   },
   "outputs": [],
   "source": [
    "# Create input and output \n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Zf-c045H0ny"
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def generate_arrays(X_all, y_all, batch_size):\n",
    "    index = 0\n",
    "    while True:\n",
    "        x = np.zeros((batch_size, X.shape[1]), dtype=np.int32)\n",
    "        y = np.zeros((batch_size, vocab_size), dtype=np.bool)\n",
    "        for i in range(batch_size):\n",
    "            x[i] = X_all[index]\n",
    "            y[i] = to_categorical(y_all[index], num_classes = vocab_size)\n",
    "\n",
    "            index = index + 1\n",
    "            if index == len(X_all):\n",
    "               index = 0\n",
    "               \n",
    "        yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5w9Ggx98E5G5"
   },
   "outputs": [],
   "source": [
    "# Create training set and test set\n",
    "def shuffle_train_test_split(X_all, y_all, shuffle=True, test_percent=20, random_state=10):\n",
    "    \n",
    "    if shuffle:\n",
    "      X_all_shuffled = []\n",
    "      y_all_shuffled = [] \n",
    "      for i in np.random.RandomState(seed=random_state).permutation(len(X_all)):\n",
    "          X_all_shuffled.append(X_all[i])\n",
    "          y_all_shuffled.append(y_all[i])\n",
    "    else:\n",
    "      X_all_shuffled = X_all\n",
    "      y_all_shuffled = y_all\n",
    "\n",
    "    split_index = int(len(X_all) * (1.-(test_percent/100.)))\n",
    "    X_train, X_test = X_all_shuffled[:split_index], X_all_shuffled[split_index:]\n",
    "    y_train, y_test = y_all_shuffled[:split_index], y_all_shuffled[split_index:]\n",
    "\n",
    "    X_train = np.array(X_train)    \n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0tlc5noHHCz"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = shuffle_train_test_split(X, y, test_percent=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CU9G9d3f7PcA"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwJUxLue7XaN"
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "_3u8x8lX5jg3",
    "outputId": "b23c99b6-997b-42fa-c249-3a79881c9c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 199, 256)          1844480   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7205)              1851685   \n",
      "=================================================================\n",
      "Total params: 4,090,405\n",
      "Trainable params: 4,090,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=SEQUENCE_LENGTH-1))\n",
    "model.add(Bidirectional(LSTM(units=RNN_UNITS)))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "model.add(Dense(units=vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yXKGPrQ8-gL5"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCEmLVPp-hqt"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaFcd95r-7tD"
   },
   "source": [
    "## Define the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gnJCiEb-9C_"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "callbacks_list = [early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UW5XlkgjAuLp"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QVryiAfHAvR8",
    "outputId": "5e17542e-86ae-4247-f472-19f0b336a872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 4476 steps\n",
      "Epoch 1/50\n",
      "4476/4476 [==============================] - 178s 40ms/step - loss: 5.7886 - accuracy: 0.1478\n",
      "Epoch 2/50\n",
      "4476/4476 [==============================] - 177s 39ms/step - loss: 5.0200 - accuracy: 0.2075\n",
      "Epoch 3/50\n",
      "4476/4476 [==============================] - 177s 40ms/step - loss: 4.5974 - accuracy: 0.2345\n",
      "Epoch 4/50\n",
      "4476/4476 [==============================] - 178s 40ms/step - loss: 4.2549 - accuracy: 0.2575\n",
      "Epoch 5/50\n",
      "4476/4476 [==============================] - 174s 39ms/step - loss: 3.9021 - accuracy: 0.2827\n",
      "Epoch 6/50\n",
      "4476/4476 [==============================] - 177s 40ms/step - loss: 3.6072 - accuracy: 0.3112\n",
      "Epoch 7/50\n",
      "4476/4476 [==============================] - 178s 40ms/step - loss: 3.2914 - accuracy: 0.3456\n",
      "Epoch 8/50\n",
      "4476/4476 [==============================] - 177s 40ms/step - loss: 3.0484 - accuracy: 0.3780\n",
      "Epoch 9/50\n",
      "4476/4476 [==============================] - 177s 40ms/step - loss: 2.7921 - accuracy: 0.4123\n",
      "Epoch 10/50\n",
      "4476/4476 [==============================] - 177s 40ms/step - loss: 2.5753 - accuracy: 0.4467\n",
      "Epoch 11/50\n",
      "4476/4476 [==============================] - 177s 40ms/step - loss: 2.3858 - accuracy: 0.4771\n",
      "Epoch 12/50\n",
      "4476/4476 [==============================] - 177s 39ms/step - loss: 2.2301 - accuracy: 0.5013\n",
      "Epoch 13/50\n",
      "4476/4476 [==============================] - 177s 39ms/step - loss: 2.0983 - accuracy: 0.5229\n",
      "Epoch 14/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.9881 - accuracy: 0.5412\n",
      "Epoch 15/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.8995 - accuracy: 0.5568\n",
      "Epoch 16/50\n",
      "4476/4476 [==============================] - 177s 39ms/step - loss: 1.8273 - accuracy: 0.5687\n",
      "Epoch 17/50\n",
      "4476/4476 [==============================] - 177s 40ms/step - loss: 1.7534 - accuracy: 0.5829\n",
      "Epoch 18/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.6770 - accuracy: 0.5958\n",
      "Epoch 19/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.6388 - accuracy: 0.6016\n",
      "Epoch 20/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.6415 - accuracy: 0.5984\n",
      "Epoch 21/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.6057 - accuracy: 0.6067\n",
      "Epoch 22/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.5799 - accuracy: 0.6096\n",
      "Epoch 23/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.7871 - accuracy: 0.5662\n",
      "Epoch 24/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.8275 - accuracy: 0.5591\n",
      "Epoch 25/50\n",
      "4476/4476 [==============================] - 177s 39ms/step - loss: 1.6277 - accuracy: 0.5986\n",
      "Epoch 26/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.5256 - accuracy: 0.6194\n",
      "Epoch 27/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.5077 - accuracy: 0.6208\n",
      "Epoch 28/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.5359 - accuracy: 0.6129\n",
      "Epoch 29/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.4758 - accuracy: 0.6264\n",
      "Epoch 30/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.4052 - accuracy: 0.6409\n",
      "Epoch 31/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.3437 - accuracy: 0.6549\n",
      "Epoch 32/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.2981 - accuracy: 0.6653\n",
      "Epoch 33/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.2575 - accuracy: 0.6731\n",
      "Epoch 34/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.2459 - accuracy: 0.6732\n",
      "Epoch 35/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.2394 - accuracy: 0.6741\n",
      "Epoch 36/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.2729 - accuracy: 0.6654\n",
      "Epoch 37/50\n",
      "4476/4476 [==============================] - 177s 40ms/step - loss: 1.2528 - accuracy: 0.6690\n",
      "Epoch 38/50\n",
      "4476/4476 [==============================] - 179s 40ms/step - loss: 1.2359 - accuracy: 0.6726\n",
      "Epoch 39/50\n",
      "4476/4476 [==============================] - 178s 40ms/step - loss: 1.1916 - accuracy: 0.6844\n",
      "Epoch 40/50\n",
      "4476/4476 [==============================] - 178s 40ms/step - loss: 1.2087 - accuracy: 0.6799\n",
      "Epoch 41/50\n",
      "4476/4476 [==============================] - 178s 40ms/step - loss: 1.1749 - accuracy: 0.6873\n",
      "Epoch 42/50\n",
      "4476/4476 [==============================] - 177s 40ms/step - loss: 1.2289 - accuracy: 0.6725\n",
      "Epoch 43/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.1443 - accuracy: 0.6924\n",
      "Epoch 44/50\n",
      "4476/4476 [==============================] - 176s 39ms/step - loss: 1.1036 - accuracy: 0.7026\n",
      "Epoch 45/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.0671 - accuracy: 0.7109\n",
      "Epoch 46/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.0423 - accuracy: 0.7170\n",
      "Epoch 47/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.0141 - accuracy: 0.7222\n",
      "Epoch 48/50\n",
      "4476/4476 [==============================] - 178s 40ms/step - loss: 1.0080 - accuracy: 0.7231\n",
      "Epoch 49/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 1.0031 - accuracy: 0.7243\n",
      "Epoch 50/50\n",
      "4476/4476 [==============================] - 175s 39ms/step - loss: 0.9847 - accuracy: 0.7285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0067e36128>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_arrays(X_train, y_train, BATCH_SIZE),\n",
    "                    steps_per_epoch = (len(X) // BATCH_SIZE) + 1,\n",
    "                    epochs = EPOCHS,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CEfCZCQzQQFo"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "__8CsMnAPMci",
    "outputId": "4b383698-517b-44c8-c4a4-5a1a7a9393dd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss curves\n",
    "fig = plt.figure()\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehJfl7-9rfU3"
   },
   "source": [
    "# Save data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tP3hHrogrjMq"
   },
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "# save the tokenizer to file\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqI19xXkMAAu"
   },
   "outputs": [],
   "source": [
    "# save sequences to file\n",
    "data = '\\n'.join(sequences_words)\n",
    "with open(\"sequences_words.txt\", 'w') as file:\n",
    "  file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbRpu-AKOuYC"
   },
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "text_generation_word_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
